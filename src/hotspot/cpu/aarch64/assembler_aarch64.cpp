/*
 * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
 * Copyright (c) 2014, 2020 Red Hat Inc. All rights reserved.
 * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 *
 * This code is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 only, as
 * published by the Free Software Foundation.
 *
 * This code is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 * version 2 for more details (a copy is included in the LICENSE file that
 * accompanied this code).
 *
 * You should have received a copy of the GNU General Public License version
 * 2 along with this work; if not, write to the Free Software Foundation,
 * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 *
 * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 * or visit www.oracle.com if you need additional information or have any
 * questions.
 */

#include <stdio.h>
#include <sys/types.h>

#include "precompiled.hpp"
#include "asm/assembler.hpp"
#include "asm/assembler.inline.hpp"
#include "interpreter/interpreter.hpp"

#ifndef PRODUCT
const uintptr_t Assembler::asm_bp = 0x00007fffee09ac88;
#endif

#include "compiler/disassembler.hpp"
#include "memory/resourceArea.hpp"
#include "runtime/interfaceSupport.inline.hpp"
#include "runtime/sharedRuntime.hpp"
#include "immediate_aarch64.hpp"

extern "C" void entry(CodeBuffer *cb);

#define __ _masm.
#ifdef PRODUCT
#define BLOCK_COMMENT(str) /* nothing */
#else
#define BLOCK_COMMENT(str) block_comment(str)
#endif

#define BIND(label) bind(label); __ BLOCK_COMMENT(#label ":")

static float unpack(unsigned value);

short Assembler::SIMD_Size_in_bytes[] = {
  // T8B, T16B, T4H, T8H, T2S, T4S, T1D, T2D, T1Q
       8,   16,   8,  16,   8,  16,   8,  16,  16
};

#ifdef ASSERT
static void asm_check(const unsigned int *insns, const unsigned int *insns1, size_t len) {
    bool ok = true;
    for (unsigned int i = 0; i < len; i++) {
      if (insns[i] != insns1[i]) {
        ok = false;
        printf("Ours:\n");
        Disassembler::decode((address)&insns1[i], (address)&insns1[i+1]);
        printf("Theirs:\n");
        Disassembler::decode((address)&insns[i], (address)&insns[i+1]);
        printf("\n");
      }
    }
    assert(ok, "Assembler smoke test failed");
  }

void entry(CodeBuffer *cb) {

  // {
  //   for (int i = 0; i < 256; i+=16)
  //     {
  //    printf("\"%20.20g\", ", unpack(i));
  //    printf("\"%20.20g\", ", unpack(i+1));
  //     }
  //   printf("\n");
  // }

  Assembler _masm(cb);
  address entry = __ pc();

  // Smoke test for assembler

// BEGIN  Generated code -- do not edit
// Generated by aarch64-asmtest.py
    Label back, forth;
    __ bind(back);

// ArithOp
    __ add(r29, r3, r6, Assembler::LSR, 47);                          //    add x29, x3, x6, LSR #47
    __ sub(r17, r0, r22, Assembler::ASR, 18);                         //    sub x17, x0, x22, ASR #18
    __ adds(r26, r24, r27, Assembler::LSL, 47);                       //    adds x26, x24, x27, LSL #47
    __ subs(r28, r24, r19, Assembler::LSL, 34);                       //    subs x28, x24, x19, LSL #34
    __ addw(r15, r24, r30, Assembler::LSL, 28);                       //    add w15, w24, w30, LSL #28
    __ subw(r4, r14, r10, Assembler::LSL, 23);                        //    sub w4, w14, w10, LSL #23
    __ addsw(r20, r2, r27, Assembler::LSL, 20);                       //    adds w20, w2, w27, LSL #20
    __ subsw(r13, r10, r2, Assembler::LSL, 28);                       //    subs w13, w10, w2, LSL #28
    __ andr(r24, r28, r17, Assembler::LSR, 4);                        //    and x24, x28, x17, LSR #4
    __ orr(r12, r22, r19, Assembler::LSR, 12);                        //    orr x12, x22, x19, LSR #12
    __ eor(r26, r16, r16, Assembler::LSR, 28);                        //    eor x26, x16, x16, LSR #28
    __ ands(r10, r16, r4, Assembler::LSR, 28);                        //    ands x10, x16, x4, LSR #28
    __ andw(r17, r17, r12, Assembler::LSR, 23);                       //    and w17, w17, w12, LSR #23
    __ orrw(r13, r3, r2, Assembler::ASR, 31);                         //    orr w13, w3, w2, ASR #31
    __ eorw(r24, r14, r7, Assembler::LSR, 24);                        //    eor w24, w14, w7, LSR #24
    __ andsw(r2, r28, r4, Assembler::ASR, 31);                        //    ands w2, w28, w4, ASR #31
    __ bic(r27, r15, r1, Assembler::ASR, 61);                         //    bic x27, x15, x1, ASR #61
    __ orn(r15, r15, r0, Assembler::LSR, 28);                         //    orn x15, x15, x0, LSR #28
    __ eon(r9, r16, r25, Assembler::LSL, 44);                         //    eon x9, x16, x25, LSL #44
    __ bics(r5, r29, r24, Assembler::LSR, 51);                        //    bics x5, x29, x24, LSR #51
    __ bicw(r16, r6, r11, Assembler::ASR, 6);                         //    bic w16, w6, w11, ASR #6
    __ ornw(r11, r25, r13, Assembler::LSL, 11);                       //    orn w11, w25, w13, LSL #11
    __ eonw(r5, r9, r26, Assembler::ASR, 10);                         //    eon w5, w9, w26, ASR #10
    __ bicsw(r2, r24, r2, Assembler::LSR, 1);                         //    bics w2, w24, w2, LSR #1

// AddSubImmOp
    __ addw(r12, r9, 558u);                                           //    add w12, w9, #558
    __ addsw(r25, r30, 94u);                                          //    adds w25, w30, #94
    __ subw(r0, r10, 727u);                                           //    sub w0, w10, #727
    __ subsw(r14, r2, 44u);                                           //    subs w14, w2, #44
    __ add(r8, r29, 522u);                                            //    add x8, x29, #522
    __ adds(r25, r9, 207u);                                           //    adds x25, x9, #207
    __ sub(r16, r8, 293u);                                            //    sub x16, x8, #293
    __ subs(r23, r1, 798u);                                           //    subs x23, x1, #798

// LogicalImmOp
    __ andw(r17, r17, 251662080ul);                                   //    and w17, w17, #0xf000f00
    __ orrw(r3, r24, 2678038431ul);                                   //    orr w3, w24, #0x9f9f9f9f
    __ eorw(r12, r27, 404232216ul);                                   //    eor w12, w27, #0x18181818
    __ andsw(r10, r30, 2147482624ul);                                 //    ands w10, w30, #0x7ffffc00
    __ andr(r12, r9, 18374686479671656447ul);                         //    and x12, x9, #0xff00000000007fff
    __ orr(r13, r12, 9241386433220968447ul);                          //    orr x13, x12, #0x803fffff803fffff
    __ eor(r20, r10, 17870287719452639231ul);                         //    eor x20, x10, #0xf80003ffffffffff
    __ ands(r1, r22, 576456354256912384ul);                           //    ands x1, x22, #0x7fffc0000000000

// AbsOp
    __ b(__ pc());                                                    //    b .
    __ b(back);                                                       //    b back
    __ b(forth);                                                      //    b forth
    __ bl(__ pc());                                                   //    bl .
    __ bl(back);                                                      //    bl back
    __ bl(forth);                                                     //    bl forth

// RegAndAbsOp
    __ cbzw(r29, __ pc());                                            //    cbz w29, .
    __ cbzw(r29, back);                                               //    cbz w29, back
    __ cbzw(r29, forth);                                              //    cbz w29, forth
    __ cbnzw(r6, __ pc());                                            //    cbnz w6, .
    __ cbnzw(r6, back);                                               //    cbnz w6, back
    __ cbnzw(r6, forth);                                              //    cbnz w6, forth
    __ cbz(r5, __ pc());                                              //    cbz x5, .
    __ cbz(r5, back);                                                 //    cbz x5, back
    __ cbz(r5, forth);                                                //    cbz x5, forth
    __ cbnz(r17, __ pc());                                            //    cbnz x17, .
    __ cbnz(r17, back);                                               //    cbnz x17, back
    __ cbnz(r17, forth);                                              //    cbnz x17, forth
    __ adr(r3, __ pc());                                              //    adr x3, .
    __ adr(r3, back);                                                 //    adr x3, back
    __ adr(r3, forth);                                                //    adr x3, forth
    __ _adrp(r2, __ pc());                                            //    adrp x2, .

// RegImmAbsOp
    __ tbz(r22, 16, __ pc());                                         //    tbz x22, #16, .
    __ tbz(r22, 16, back);                                            //    tbz x22, #16, back
    __ tbz(r22, 16, forth);                                           //    tbz x22, #16, forth
    __ tbnz(r21, 2, __ pc());                                         //    tbnz x21, #2, .
    __ tbnz(r21, 2, back);                                            //    tbnz x21, #2, back
    __ tbnz(r21, 2, forth);                                           //    tbnz x21, #2, forth

// MoveWideImmOp
    __ movnw(r9, 28525, 0);                                           //    movn w9, #28525, lsl 0
    __ movzw(r27, 7097, 16);                                          //    movz w27, #7097, lsl 16
    __ movkw(r13, 3226, 0);                                           //    movk w13, #3226, lsl 0
    __ movn(r10, 4251, 48);                                           //    movn x10, #4251, lsl 48
    __ movz(r9, 28321, 32);                                           //    movz x9, #28321, lsl 32
    __ movk(r22, 20480, 16);                                          //    movk x22, #20480, lsl 16

// BitfieldOp
    __ sbfm(r23, r19, 28, 28);                                        //    sbfm x23, x19, #28, #28
    __ bfmw(r12, r8, 10, 12);                                         //    bfm w12, w8, #10, #12
    __ ubfmw(r8, r9, 8, 7);                                           //    ubfm w8, w9, #8, #7
    __ sbfm(r13, r1, 8, 3);                                           //    sbfm x13, x1, #8, #3
    __ bfm(r12, r21, 3, 24);                                          //    bfm x12, x21, #3, #24
    __ ubfm(r20, r16, 22, 14);                                        //    ubfm x20, x16, #22, #14

// ExtractOp
    __ extrw(r9, r6, r4, 26);                                         //    extr w9, w6, w4, #26
    __ extr(r15, r9, r4, 43);                                         //    extr x15, x9, x4, #43

// CondBranchOp
    __ br(Assembler::EQ, __ pc());                                    //    b.EQ .
    __ br(Assembler::EQ, back);                                       //    b.EQ back
    __ br(Assembler::EQ, forth);                                      //    b.EQ forth
    __ br(Assembler::NE, __ pc());                                    //    b.NE .
    __ br(Assembler::NE, back);                                       //    b.NE back
    __ br(Assembler::NE, forth);                                      //    b.NE forth
    __ br(Assembler::HS, __ pc());                                    //    b.HS .
    __ br(Assembler::HS, back);                                       //    b.HS back
    __ br(Assembler::HS, forth);                                      //    b.HS forth
    __ br(Assembler::CS, __ pc());                                    //    b.CS .
    __ br(Assembler::CS, back);                                       //    b.CS back
    __ br(Assembler::CS, forth);                                      //    b.CS forth
    __ br(Assembler::LO, __ pc());                                    //    b.LO .
    __ br(Assembler::LO, back);                                       //    b.LO back
    __ br(Assembler::LO, forth);                                      //    b.LO forth
    __ br(Assembler::CC, __ pc());                                    //    b.CC .
    __ br(Assembler::CC, back);                                       //    b.CC back
    __ br(Assembler::CC, forth);                                      //    b.CC forth
    __ br(Assembler::MI, __ pc());                                    //    b.MI .
    __ br(Assembler::MI, back);                                       //    b.MI back
    __ br(Assembler::MI, forth);                                      //    b.MI forth
    __ br(Assembler::PL, __ pc());                                    //    b.PL .
    __ br(Assembler::PL, back);                                       //    b.PL back
    __ br(Assembler::PL, forth);                                      //    b.PL forth
    __ br(Assembler::VS, __ pc());                                    //    b.VS .
    __ br(Assembler::VS, back);                                       //    b.VS back
    __ br(Assembler::VS, forth);                                      //    b.VS forth
    __ br(Assembler::VC, __ pc());                                    //    b.VC .
    __ br(Assembler::VC, back);                                       //    b.VC back
    __ br(Assembler::VC, forth);                                      //    b.VC forth
    __ br(Assembler::HI, __ pc());                                    //    b.HI .
    __ br(Assembler::HI, back);                                       //    b.HI back
    __ br(Assembler::HI, forth);                                      //    b.HI forth
    __ br(Assembler::LS, __ pc());                                    //    b.LS .
    __ br(Assembler::LS, back);                                       //    b.LS back
    __ br(Assembler::LS, forth);                                      //    b.LS forth
    __ br(Assembler::GE, __ pc());                                    //    b.GE .
    __ br(Assembler::GE, back);                                       //    b.GE back
    __ br(Assembler::GE, forth);                                      //    b.GE forth
    __ br(Assembler::LT, __ pc());                                    //    b.LT .
    __ br(Assembler::LT, back);                                       //    b.LT back
    __ br(Assembler::LT, forth);                                      //    b.LT forth
    __ br(Assembler::GT, __ pc());                                    //    b.GT .
    __ br(Assembler::GT, back);                                       //    b.GT back
    __ br(Assembler::GT, forth);                                      //    b.GT forth
    __ br(Assembler::LE, __ pc());                                    //    b.LE .
    __ br(Assembler::LE, back);                                       //    b.LE back
    __ br(Assembler::LE, forth);                                      //    b.LE forth
    __ br(Assembler::AL, __ pc());                                    //    b.AL .
    __ br(Assembler::AL, back);                                       //    b.AL back
    __ br(Assembler::AL, forth);                                      //    b.AL forth
    __ br(Assembler::NV, __ pc());                                    //    b.NV .
    __ br(Assembler::NV, back);                                       //    b.NV back
    __ br(Assembler::NV, forth);                                      //    b.NV forth

// ImmOp
    __ svc(13744);                                                    //    svc #13744
    __ hvc(31976);                                                    //    hvc #31976
    __ smc(32209);                                                    //    smc #32209
    __ brk(8815);                                                     //    brk #8815
    __ hlt(28560);                                                    //    hlt #28560

// Op
    __ nop();                                                         //    nop
    __ eret();                                                        //    eret
    __ drps();                                                        //    drps
    __ isb();                                                         //    isb

// SystemOp
    __ dsb(Assembler::NSH);                                           //    dsb NSH
    __ dmb(Assembler::SY);                                            //    dmb SY

// OneRegOp
    __ br(r29);                                                       //    br x29
    __ blr(r12);                                                      //    blr x12

// LoadStoreExclusiveOp
    __ stxr(r15, r30, r9);                                            //    stxr w15, x30, [x9]
    __ stlxr(r21, r5, r22);                                           //    stlxr w21, x5, [x22]
    __ ldxr(r14, r0);                                                 //    ldxr x14, [x0]
    __ ldaxr(r24, r0);                                                //    ldaxr x24, [x0]
    __ stlr(r25, r19);                                                //    stlr x25, [x19]
    __ ldar(r24, r10);                                                //    ldar x24, [x10]

// LoadStoreExclusiveOp
    __ stxrw(r10, r21, r17);                                          //    stxr w10, w21, [x17]
    __ stlxrw(r17, r27, r6);                                          //    stlxr w17, w27, [x6]
    __ ldxrw(r4, r29);                                                //    ldxr w4, [x29]
    __ ldaxrw(r1, r17);                                               //    ldaxr w1, [x17]
    __ stlrw(r14, r23);                                               //    stlr w14, [x23]
    __ ldarw(r22, r23);                                               //    ldar w22, [x23]

// LoadStoreExclusiveOp
    __ stxrh(r21, r0, r25);                                           //    stxrh w21, w0, [x25]
    __ stlxrh(r24, r21, r9);                                          //    stlxrh w24, w21, [x9]
    __ ldxrh(r12, r25);                                               //    ldxrh w12, [x25]
    __ ldaxrh(r11, r1);                                               //    ldaxrh w11, [x1]
    __ stlrh(r30, r11);                                               //    stlrh w30, [x11]
    __ ldarh(r8, r13);                                                //    ldarh w8, [x13]

// LoadStoreExclusiveOp
    __ stxrb(r27, r3, r28);                                           //    stxrb w27, w3, [x28]
    __ stlxrb(r3, r24, r15);                                          //    stlxrb w3, w24, [x15]
    __ ldxrb(r13, r2);                                                //    ldxrb w13, [x2]
    __ ldaxrb(r10, r30);                                              //    ldaxrb w10, [x30]
    __ stlrb(r7, r15);                                                //    stlrb w7, [x15]
    __ ldarb(r15, r8);                                                //    ldarb w15, [x8]

// LoadStoreExclusiveOp
    __ ldxp(r4, r25, r10);                                            //    ldxp x4, x25, [x10]
    __ ldaxp(r11, r28, r9);                                           //    ldaxp x11, x28, [x9]
    __ stxp(r17, r6, r16, r9);                                        //    stxp w17, x6, x16, [x9]
    __ stlxp(r17, r13, r8, r2);                                       //    stlxp w17, x13, x8, [x2]

// LoadStoreExclusiveOp
    __ ldxpw(r9, r10, r1);                                            //    ldxp w9, w10, [x1]
    __ ldaxpw(r2, r7, r11);                                           //    ldaxp w2, w7, [x11]
    __ stxpw(r2, r28, r23, r25);                                      //    stxp w2, w28, w23, [x25]
    __ stlxpw(r22, r19, r25, r20);                                    //    stlxp w22, w19, w25, [x20]

// base_plus_unscaled_offset
// LoadStoreOp
    __ str(r23, Address(r15, -215));                                  //    str x23, [x15, -215]
    __ strw(r5, Address(r8, -49));                                    //    str w5, [x8, -49]
    __ strb(r22, Address(r16, -7));                                   //    strb w22, [x16, -7]
    __ strh(r16, Address(r3, -5));                                    //    strh w16, [x3, -5]
    __ ldr(r25, Address(r5, -47));                                    //    ldr x25, [x5, -47]
    __ ldrw(r11, Address(r14, -114));                                 //    ldr w11, [x14, -114]
    __ ldrb(r25, Address(r8, -9));                                    //    ldrb w25, [x8, -9]
    __ ldrh(r22, Address(r7, -49));                                   //    ldrh w22, [x7, -49]
    __ ldrsb(r28, Address(r9, -16));                                  //    ldrsb x28, [x9, -16]
    __ ldrsh(r27, Address(r24, -34));                                 //    ldrsh x27, [x24, -34]
    __ ldrshw(r6, Address(r22, 30));                                  //    ldrsh w6, [x22, 30]
    __ ldrsw(r17, Address(r13, -71));                                 //    ldrsw x17, [x13, -71]
    __ ldrd(v3, Address(r30, -159));                                  //    ldr d3, [x30, -159]
    __ ldrs(v4, Address(r30, -3));                                    //    ldr s4, [x30, -3]
    __ strd(v6, Address(r9, -107));                                   //    str d6, [x9, -107]
    __ strs(v22, Address(r21, -72));                                  //    str s22, [x21, -72]

// pre
// LoadStoreOp
    __ str(r14, Address(__ pre(r0, -256)));                           //    str x14, [x0, -256]!
    __ strw(r14, Address(__ pre(r21, -31)));                          //    str w14, [x21, -31]!
    __ strb(r14, Address(__ pre(r8, -27)));                           //    strb w14, [x8, -27]!
    __ strh(r11, Address(__ pre(r30, -54)));                          //    strh w11, [x30, -54]!
    __ ldr(r8, Address(__ pre(r5, -27)));                             //    ldr x8, [x5, -27]!
    __ ldrw(r10, Address(__ pre(r21, -109)));                         //    ldr w10, [x21, -109]!
    __ ldrb(r7, Address(__ pre(r29, 4)));                             //    ldrb w7, [x29, 4]!
    __ ldrh(r2, Address(__ pre(r22, 26)));                            //    ldrh w2, [x22, 26]!
    __ ldrsb(r16, Address(__ pre(r4, -6)));                           //    ldrsb x16, [x4, -6]!
    __ ldrsh(r8, Address(__ pre(r15, 14)));                           //    ldrsh x8, [x15, 14]!
    __ ldrshw(r25, Address(__ pre(r14, -38)));                        //    ldrsh w25, [x14, -38]!
    __ ldrsw(r24, Address(__ pre(r29, 24)));                          //    ldrsw x24, [x29, 24]!
    __ ldrd(v8, Address(__ pre(r21, -94)));                           //    ldr d8, [x21, -94]!
    __ ldrs(v17, Address(__ pre(r14, 48)));                           //    ldr s17, [x14, 48]!
    __ strd(v25, Address(__ pre(r28, -45)));                          //    str d25, [x28, -45]!
    __ strs(v15, Address(__ pre(r12, 29)));                           //    str s15, [x12, 29]!

// post
// LoadStoreOp
    __ str(r5, Address(__ post(r7, -125)));                           //    str x5, [x7], -125
    __ strw(r6, Address(__ post(r29, -40)));                          //    str w6, [x29], -40
    __ strb(r16, Address(__ post(r0, 12)));                           //    strb w16, [x0], 12
    __ strh(r24, Address(__ post(r15, 14)));                          //    strh w24, [x15], 14
    __ ldr(r25, Address(__ post(r29, -62)));                          //    ldr x25, [x29], -62
    __ ldrw(r28, Address(__ post(r17, -1)));                          //    ldr w28, [x17], -1
    __ ldrb(r9, Address(__ post(r20, -3)));                           //    ldrb w9, [x20], -3
    __ ldrh(r30, Address(__ post(r29, -57)));                         //    ldrh w30, [x29], -57
    __ ldrsb(r6, Address(__ post(r27, -21)));                         //    ldrsb x6, [x27], -21
    __ ldrsh(r21, Address(__ post(r11, -41)));                        //    ldrsh x21, [x11], -41
    __ ldrshw(r13, Address(__ post(r10, 4)));                         //    ldrsh w13, [x10], 4
    __ ldrsw(r9, Address(__ post(r25, -88)));                         //    ldrsw x9, [x25], -88
    __ ldrd(v14, Address(__ post(r14, -90)));                         //    ldr d14, [x14], -90
    __ ldrs(v9, Address(__ post(r17, -43)));                          //    ldr s9, [x17], -43
    __ strd(v17, Address(__ post(r1, -217)));                         //    str d17, [x1], -217
    __ strs(v11, Address(__ post(r11, -72)));                         //    str s11, [x11], -72

// base_plus_reg
// LoadStoreOp
    __ str(r1, Address(r9, r26, Address::lsl(0)));                    //    str x1, [x9, x26, lsl #0]
    __ strw(r17, Address(r0, r1, Address::uxtw(0)));                  //    str w17, [x0, w1, uxtw #0]
    __ strb(r9, Address(r4, r17, Address::uxtw(0)));                  //    strb w9, [x4, w17, uxtw #0]
    __ strh(r0, Address(r30, r24, Address::sxtw(0)));                 //    strh w0, [x30, w24, sxtw #0]
    __ ldr(r0, Address(r15, r27, Address::sxtx(0)));                  //    ldr x0, [x15, x27, sxtx #0]
    __ ldrw(r19, Address(r20, r19, Address::sxtx(0)));                //    ldr w19, [x20, x19, sxtx #0]
    __ ldrb(r14, Address(r17, r17, Address::sxtx(0)));                //    ldrb w14, [x17, x17, sxtx #0]
    __ ldrh(r2, Address(r2, r9, Address::sxtx(0)));                   //    ldrh w2, [x2, x9, sxtx #0]
    __ ldrsb(r25, Address(r15, r14, Address::uxtw(0)));               //    ldrsb x25, [x15, w14, uxtw #0]
    __ ldrsh(r17, Address(r17, r3, Address::sxtw(1)));                //    ldrsh x17, [x17, w3, sxtw #1]
    __ ldrshw(r26, Address(r24, r1, Address::lsl(1)));                //    ldrsh w26, [x24, x1, lsl #1]
    __ ldrsw(r27, Address(r12, r27, Address::sxtx(2)));               //    ldrsw x27, [x12, x27, sxtx #2]
    __ ldrd(v23, Address(r9, r22, Address::sxtw(0)));                 //    ldr d23, [x9, w22, sxtw #0]
    __ ldrs(v5, Address(r7, r13, Address::sxtx(2)));                  //    ldr s5, [x7, x13, sxtx #2]
    __ strd(v15, Address(r2, r25, Address::sxtx(3)));                 //    str d15, [x2, x25, sxtx #3]
    __ strs(v22, Address(r22, r29, Address::lsl(0)));                 //    str s22, [x22, x29, lsl #0]

// base_plus_scaled_offset
// LoadStoreOp
    __ str(r17, Address(r23, 15472));                                 //    str x17, [x23, 15472]
    __ strw(r27, Address(r28, 7280));                                 //    str w27, [x28, 7280]
    __ strb(r8, Address(r24, 1676));                                  //    strb w8, [x24, 1676]
    __ strh(r23, Address(r13, 3582));                                 //    strh w23, [x13, 3582]
    __ ldr(r15, Address(r27, 15568));                                 //    ldr x15, [x27, 15568]
    __ ldrw(r24, Address(r17, 8092));                                 //    ldr w24, [x17, 8092]
    __ ldrb(r2, Address(r7, 1636));                                   //    ldrb w2, [x7, 1636]
    __ ldrh(r14, Address(r15, 4020));                                 //    ldrh w14, [x15, 4020]
    __ ldrsb(r12, Address(r25, 1796));                                //    ldrsb x12, [x25, 1796]
    __ ldrsh(r5, Address(r20, 4024));                                 //    ldrsh x5, [x20, 4024]
    __ ldrshw(r28, Address(r25, 3376));                               //    ldrsh w28, [x25, 3376]
    __ ldrsw(r17, Address(r0, 6540));                                 //    ldrsw x17, [x0, 6540]
    __ ldrd(v22, Address(r11, 15696));                                //    ldr d22, [x11, 15696]
    __ ldrs(v27, Address(r17, 6820));                                 //    ldr s27, [x17, 6820]
    __ strd(v5, Address(r23, 14864));                                 //    str d5, [x23, 14864]
    __ strs(v2, Address(r9, 7832));                                   //    str s2, [x9, 7832]

// pcrel
// LoadStoreOp
    __ ldr(r14, __ pc());                                             //    ldr x14, .
    __ ldrw(r4, __ pc());                                             //    ldr w4, .

// LoadStoreOp
    __ prfm(Address(r5, -165));                                       //    prfm PLDL1KEEP, [x5, -165]

// LoadStoreOp
    __ prfm(forth);                                                   //    prfm PLDL1KEEP, forth

// LoadStoreOp
    __ prfm(Address(r13, r4, Address::lsl(0)));                       //    prfm PLDL1KEEP, [x13, x4, lsl #0]

// LoadStoreOp
    __ prfm(Address(r0, 12992));                                      //    prfm PLDL1KEEP, [x0, 12992]

// AddSubCarryOp
    __ adcw(r30, r12, r9);                                            //    adc w30, w12, w9
    __ adcsw(r25, r9, r20);                                           //    adcs w25, w9, w20
    __ sbcw(r5, r3, r5);                                              //    sbc w5, w3, w5
    __ sbcsw(r12, r2, r13);                                           //    sbcs w12, w2, w13
    __ adc(r1, r20, r6);                                              //    adc x1, x20, x6
    __ adcs(r20, r16, r4);                                            //    adcs x20, x16, x4
    __ sbc(r12, r9, r13);                                             //    sbc x12, x9, x13
    __ sbcs(r17, r27, r24);                                           //    sbcs x17, x27, x24

// AddSubExtendedOp
    __ addw(r5, r16, r7, ext::sxtb, 4);                               //    add w5, w16, w7, sxtb #4
    __ addsw(r19, r27, r28, ext::sxtw, 2);                            //    adds w19, w27, w28, sxtw #2
    __ sub(r14, r23, r26, ext::sxtw, 1);                              //    sub x14, x23, x26, sxtw #1
    __ subsw(r29, r19, r1, ext::sxtx, 1);                             //    subs w29, w19, w1, sxtx #1
    __ add(r0, r15, r2, ext::uxtw, 3);                                //    add x0, x15, x2, uxtw #3
    __ adds(r27, r19, r3, ext::sxth, 2);                              //    adds x27, x19, x3, sxth #2
    __ sub(r2, r21, r28, ext::sxtw, 3);                               //    sub x2, x21, x28, sxtw #3
    __ subs(r14, r4, r15, ext::sxth, 1);                              //    subs x14, x4, x15, sxth #1

// ConditionalCompareOp
    __ ccmnw(r21, r15, 13u, Assembler::LO);                           //    ccmn w21, w15, #13, LO
    __ ccmpw(r15, r15, 8u, Assembler::CC);                            //    ccmp w15, w15, #8, CC
    __ ccmn(r27, r9, 7u, Assembler::LE);                              //    ccmn x27, x9, #7, LE
    __ ccmp(r19, r10, 9u, Assembler::HS);                             //    ccmp x19, x10, #9, HS

// ConditionalCompareImmedOp
    __ ccmnw(r11, 10, 0, Assembler::GT);                              //    ccmn w11, #10, #0, GT
    __ ccmpw(r17, 14, 7, Assembler::LO);                              //    ccmp w17, #14, #7, LO
    __ ccmn(r22, 27, 14, Assembler::EQ);                              //    ccmn x22, #27, #14, EQ
    __ ccmp(r2, 7, 4, Assembler::LE);                                 //    ccmp x2, #7, #4, LE

// ConditionalSelectOp
    __ cselw(r4, r4, r17, Assembler::VS);                             //    csel w4, w4, w17, VS
    __ csincw(r26, r17, r2, Assembler::CS);                           //    csinc w26, w17, w2, CS
    __ csinvw(r13, r2, r14, Assembler::LT);                           //    csinv w13, w2, w14, LT
    __ csnegw(r3, r30, r30, Assembler::VC);                           //    csneg w3, w30, w30, VC
    __ csel(r26, r28, r10, Assembler::NE);                            //    csel x26, x28, x10, NE
    __ csinc(r14, r1, r16, Assembler::VS);                            //    csinc x14, x1, x16, VS
    __ csinv(r11, r1, r5, Assembler::NE);                             //    csinv x11, x1, x5, NE
    __ csneg(r5, r21, r14, Assembler::VC);                            //    csneg x5, x21, x14, VC

// TwoRegOp
    __ rbitw(r5, r12);                                                //    rbit w5, w12
    __ rev16w(r16, r16);                                              //    rev16 w16, w16
    __ revw(r8, r29);                                                 //    rev w8, w29
    __ clzw(r25, r14);                                                //    clz w25, w14
    __ clsw(r26, r0);                                                 //    cls w26, w0
    __ rbit(r28, r7);                                                 //    rbit x28, x7
    __ rev16(r8, r0);                                                 //    rev16 x8, x0
    __ rev32(r2, r21);                                                //    rev32 x2, x21
    __ rev(r5, r1);                                                   //    rev x5, x1
    __ clz(r8, r28);                                                  //    clz x8, x28
    __ cls(r17, r10);                                                 //    cls x17, x10

// ThreeRegOp
    __ udivw(r3, r11, r26);                                           //    udiv w3, w11, w26
    __ sdivw(r2, r27, r19);                                           //    sdiv w2, w27, w19
    __ lslvw(r12, r10, r23);                                          //    lslv w12, w10, w23
    __ lsrvw(r23, r17, r4);                                           //    lsrv w23, w17, w4
    __ asrvw(r21, r13, r8);                                           //    asrv w21, w13, w8
    __ rorvw(r16, r13, r4);                                           //    rorv w16, w13, w4
    __ udiv(r23, r8, r4);                                             //    udiv x23, x8, x4
    __ sdiv(r7, r8, r16);                                             //    sdiv x7, x8, x16
    __ lslv(r17, r20, r8);                                            //    lslv x17, x20, x8
    __ lsrv(r7, r15, r22);                                            //    lsrv x7, x15, x22
    __ asrv(r10, r19, r24);                                           //    asrv x10, x19, x24
    __ rorv(r23, r11, r0);                                            //    rorv x23, x11, x0
    __ umulh(r4, r2, r4);                                             //    umulh x4, x2, x4
    __ smulh(r3, r24, r16);                                           //    smulh x3, x24, x16

// FourRegMulOp
    __ maddw(r29, r30, r10, r8);                                      //    madd w29, w30, w10, w8
    __ msubw(r28, r4, r7, r28);                                       //    msub w28, w4, w7, w28
    __ madd(r26, r12, r26, r25);                                      //    madd x26, x12, x26, x25
    __ msub(r11, r25, r23, r6);                                       //    msub x11, x25, x23, x6
    __ smaddl(r17, r19, r11, r9);                                     //    smaddl x17, w19, w11, x9
    __ smsubl(r11, r15, r13, r9);                                     //    smsubl x11, w15, w13, x9
    __ umaddl(r22, r23, r3, r0);                                      //    umaddl x22, w23, w3, x0
    __ umsubl(r14, r1, r15, r15);                                     //    umsubl x14, w1, w15, x15

// ThreeRegFloatOp
    __ fmuls(v15, v16, v2);                                           //    fmul s15, s16, s2
    __ fdivs(v2, v24, v22);                                           //    fdiv s2, s24, s22
    __ fadds(v17, v21, v19);                                          //    fadd s17, s21, s19
    __ fsubs(v26, v25, v28);                                          //    fsub s26, s25, s28
    __ fmuls(v9, v16, v12);                                           //    fmul s9, s16, s12
    __ fmuld(v26, v15, v5);                                           //    fmul d26, d15, d5
    __ fdivd(v26, v16, v3);                                           //    fdiv d26, d16, d3
    __ faddd(v13, v12, v1);                                           //    fadd d13, d12, d1
    __ fsubd(v17, v2, v12);                                           //    fsub d17, d2, d12
    __ fmuld(v11, v22, v0);                                           //    fmul d11, d22, d0

// FourRegFloatOp
    __ fmadds(v10, v4, v25, v15);                                     //    fmadd s10, s4, s25, s15
    __ fmsubs(v27, v20, v27, v2);                                     //    fmsub s27, s20, s27, s2
    __ fnmadds(v30, v17, v23, v27);                                   //    fnmadd s30, s17, s23, s27
    __ fnmadds(v14, v25, v5, v14);                                    //    fnmadd s14, s25, s5, s14
    __ fmaddd(v17, v6, v22, v19);                                     //    fmadd d17, d6, d22, d19
    __ fmsubd(v29, v1, v15, v16);                                     //    fmsub d29, d1, d15, d16
    __ fnmaddd(v14, v8, v19, v23);                                    //    fnmadd d14, d8, d19, d23
    __ fnmaddd(v15, v22, v1, v10);                                    //    fnmadd d15, d22, d1, d10

// TwoRegFloatOp
    __ fmovs(v26, v13);                                               //    fmov s26, s13
    __ fabss(v13, v3);                                                //    fabs s13, s3
    __ fnegs(v17, v21);                                               //    fneg s17, s21
    __ fsqrts(v20, v27);                                              //    fsqrt s20, s27
    __ fcvts(v4, v24);                                                //    fcvt d4, s24
    __ fmovd(v12, v21);                                               //    fmov d12, d21
    __ fabsd(v5, v23);                                                //    fabs d5, d23
    __ fnegd(v17, v4);                                                //    fneg d17, d4
    __ fsqrtd(v11, v5);                                               //    fsqrt d11, d5
    __ fcvtd(v12, v19);                                               //    fcvt s12, d19

// FloatConvertOp
    __ fcvtzsw(r3, v26);                                              //    fcvtzs w3, s26
    __ fcvtzs(r30, v29);                                              //    fcvtzs x30, s29
    __ fcvtzdw(r11, v11);                                             //    fcvtzs w11, d11
    __ fcvtzd(r21, v7);                                               //    fcvtzs x21, d7
    __ scvtfws(v4, r30);                                              //    scvtf s4, w30
    __ scvtfs(v28, r10);                                              //    scvtf s28, x10
    __ scvtfwd(v13, r1);                                              //    scvtf d13, w1
    __ scvtfd(v11, r9);                                               //    scvtf d11, x9
    __ fmovs(r15, v23);                                               //    fmov w15, s23
    __ fmovd(r17, v17);                                               //    fmov x17, d17
    __ fmovs(v24, r15);                                               //    fmov s24, w15
    __ fmovd(v24, r17);                                               //    fmov d24, x17

// TwoRegFloatOp
    __ fcmps(v29, v8);                                                //    fcmp s29, s8
    __ fcmpd(v3, v21);                                                //    fcmp d3, d21
    __ fcmps(v0, 0.0);                                                //    fcmp s0, #0.0
    __ fcmpd(v9, 0.0);                                                //    fcmp d9, #0.0

// LoadStorePairOp
    __ stpw(r14, r2, Address(r22, 0));                                //    stp w14, w2, [x22, #0]
    __ ldpw(r10, r30, Address(r22, 112));                             //    ldp w10, w30, [x22, #112]
    __ ldpsw(r9, r30, Address(r9, -96));                              //    ldpsw x9, x30, [x9, #-96]
    __ stp(r7, r27, Address(r13, 128));                               //    stp x7, x27, [x13, #128]
    __ ldp(r26, r21, Address(r20, -128));                             //    ldp x26, x21, [x20, #-128]

// LoadStorePairOp
    __ stpw(r21, r17, Address(__ pre(r22, -208)));                    //    stp w21, w17, [x22, #-208]!
    __ ldpw(r8, r14, Address(__ pre(r5, -240)));                      //    ldp w8, w14, [x5, #-240]!
    __ ldpsw(r15, r21, Address(__ pre(r3, -224)));                    //    ldpsw x15, x21, [x3, #-224]!
    __ stp(r10, r10, Address(__ pre(r30, -240)));                     //    stp x10, x10, [x30, #-240]!
    __ ldp(r6, r5, Address(__ pre(r29, -240)));                       //    ldp x6, x5, [x29, #-240]!

// LoadStorePairOp
    __ stpw(r2, r20, Address(__ post(r17, -32)));                     //    stp w2, w20, [x17], #-32
    __ ldpw(r16, r5, Address(__ post(r12, -176)));                    //    ldp w16, w5, [x12], #-176
    __ ldpsw(r29, r12, Address(__ post(r30, 48)));                    //    ldpsw x29, x12, [x30], #48
    __ stp(r23, r24, Address(__ post(r8, 112)));                      //    stp x23, x24, [x8], #112
    __ ldp(r4, r6, Address(__ post(r28, -96)));                       //    ldp x4, x6, [x28], #-96

// LoadStorePairOp
    __ stnpw(r6, r2, Address(r19, 16));                               //    stnp w6, w2, [x19, #16]
    __ ldnpw(r5, r11, Address(r27, 80));                              //    ldnp w5, w11, [x27, #80]
    __ stnp(r12, r19, Address(r1, 96));                               //    stnp x12, x19, [x1, #96]
    __ ldnp(r5, r16, Address(r21, 16));                               //    ldnp x5, x16, [x21, #16]

// LdStSIMDOp
    __ ld1(v28, __ T8B, Address(r20));                                //    ld1 {v28.8B}, [x20]
    __ ld1(v25, v26, __ T16B, Address(__ post(r3, 32)));              //    ld1 {v25.16B, v26.16B}, [x3], 32
    __ ld1(v30, v31, v0, __ T1D, Address(__ post(r25, r10)));         //    ld1 {v30.1D, v31.1D, v0.1D}, [x25], x10
    __ ld1(v19, v20, v21, v22, __ T8H, Address(__ post(r5, 64)));     //    ld1 {v19.8H, v20.8H, v21.8H, v22.8H}, [x5], 64
    __ ld1r(v12, __ T8B, Address(r26));                               //    ld1r {v12.8B}, [x26]
    __ ld1r(v13, __ T4S, Address(__ post(r27, 4)));                   //    ld1r {v13.4S}, [x27], 4
    __ ld1r(v26, __ T1D, Address(__ post(r8, r8)));                   //    ld1r {v26.1D}, [x8], x8
    __ ld2(v27, v28, __ T2D, Address(r24));                           //    ld2 {v27.2D, v28.2D}, [x24]
    __ ld2(v1, v2, __ T4H, Address(__ post(r8, 16)));                 //    ld2 {v1.4H, v2.4H}, [x8], 16
    __ ld2r(v9, v10, __ T16B, Address(r7));                           //    ld2r {v9.16B, v10.16B}, [x7]
    __ ld2r(v12, v13, __ T2S, Address(__ post(r4, 8)));               //    ld2r {v12.2S, v13.2S}, [x4], 8
    __ ld2r(v0, v1, __ T2D, Address(__ post(r3, r13)));               //    ld2r {v0.2D, v1.2D}, [x3], x13
    __ ld3(v22, v23, v24, __ T4S, Address(__ post(r6, r19)));         //    ld3 {v22.4S, v23.4S, v24.4S}, [x6], x19
    __ ld3(v3, v4, v5, __ T2S, Address(r8));                          //    ld3 {v3.2S, v4.2S, v5.2S}, [x8]
    __ ld3r(v11, v12, v13, __ T8H, Address(r8));                      //    ld3r {v11.8H, v12.8H, v13.8H}, [x8]
    __ ld3r(v16, v17, v18, __ T4S, Address(__ post(r30, 12)));        //    ld3r {v16.4S, v17.4S, v18.4S}, [x30], 12
    __ ld3r(v28, v29, v30, __ T1D, Address(__ post(r14, r13)));       //    ld3r {v28.1D, v29.1D, v30.1D}, [x14], x13
    __ ld4(v0, v1, v2, v3, __ T8H, Address(__ post(r26, 64)));        //    ld4 {v0.8H, v1.8H, v2.8H, v3.8H}, [x26], 64
    __ ld4(v1, v2, v3, v4, __ T8B, Address(__ post(r22, r17)));       //    ld4 {v1.8B, v2.8B, v3.8B, v4.8B}, [x22], x17
    __ ld4r(v1, v2, v3, v4, __ T8B, Address(r17));                    //    ld4r {v1.8B, v2.8B, v3.8B, v4.8B}, [x17]
    __ ld4r(v23, v24, v25, v26, __ T4H, Address(__ post(r19, 8)));    //    ld4r {v23.4H, v24.4H, v25.4H, v26.4H}, [x19], 8
    __ ld4r(v27, v28, v29, v30, __ T2S, Address(__ post(r4, r3)));    //    ld4r {v27.2S, v28.2S, v29.2S, v30.2S}, [x4], x3

// SpecialCases
    __ ccmn(zr, zr, 3u, Assembler::LE);                               //    ccmn xzr, xzr, #3, LE
    __ ccmnw(zr, zr, 5u, Assembler::EQ);                              //    ccmn wzr, wzr, #5, EQ
    __ ccmp(zr, 1, 4u, Assembler::NE);                                //    ccmp xzr, 1, #4, NE
    __ ccmpw(zr, 2, 2, Assembler::GT);                                //    ccmp wzr, 2, #2, GT
    __ extr(zr, zr, zr, 0);                                           //    extr xzr, xzr, xzr, 0
    __ stlxp(r0, zr, zr, sp);                                         //    stlxp w0, xzr, xzr, [sp]
    __ stlxpw(r2, zr, zr, r3);                                        //    stlxp w2, wzr, wzr, [x3]
    __ stxp(r4, zr, zr, r5);                                          //    stxp w4, xzr, xzr, [x5]
    __ stxpw(r6, zr, zr, sp);                                         //    stxp w6, wzr, wzr, [sp]
    __ dup(v0, __ T16B, zr);                                          //    dup v0.16b, wzr
    __ mov(v1, __ T1D, 0, zr);                                        //    mov v1.d[0], xzr
    __ mov(v1, __ T2S, 1, zr);                                        //    mov v1.s[1], wzr
    __ mov(v1, __ T4H, 2, zr);                                        //    mov v1.h[2], wzr
    __ mov(v1, __ T8B, 3, zr);                                        //    mov v1.b[3], wzr
    __ ld1(v31, v0, __ T2D, Address(__ post(r1, r0)));                //    ld1 {v31.2d, v0.2d}, [x1], x0

// FloatImmediateOp
    __ fmovd(v0, 2.0);                                                //    fmov d0, #2.0
    __ fmovd(v0, 2.125);                                              //    fmov d0, #2.125
    __ fmovd(v0, 4.0);                                                //    fmov d0, #4.0
    __ fmovd(v0, 4.25);                                               //    fmov d0, #4.25
    __ fmovd(v0, 8.0);                                                //    fmov d0, #8.0
    __ fmovd(v0, 8.5);                                                //    fmov d0, #8.5
    __ fmovd(v0, 16.0);                                               //    fmov d0, #16.0
    __ fmovd(v0, 17.0);                                               //    fmov d0, #17.0
    __ fmovd(v0, 0.125);                                              //    fmov d0, #0.125
    __ fmovd(v0, 0.1328125);                                          //    fmov d0, #0.1328125
    __ fmovd(v0, 0.25);                                               //    fmov d0, #0.25
    __ fmovd(v0, 0.265625);                                           //    fmov d0, #0.265625
    __ fmovd(v0, 0.5);                                                //    fmov d0, #0.5
    __ fmovd(v0, 0.53125);                                            //    fmov d0, #0.53125
    __ fmovd(v0, 1.0);                                                //    fmov d0, #1.0
    __ fmovd(v0, 1.0625);                                             //    fmov d0, #1.0625
    __ fmovd(v0, -2.0);                                               //    fmov d0, #-2.0
    __ fmovd(v0, -2.125);                                             //    fmov d0, #-2.125
    __ fmovd(v0, -4.0);                                               //    fmov d0, #-4.0
    __ fmovd(v0, -4.25);                                              //    fmov d0, #-4.25
    __ fmovd(v0, -8.0);                                               //    fmov d0, #-8.0
    __ fmovd(v0, -8.5);                                               //    fmov d0, #-8.5
    __ fmovd(v0, -16.0);                                              //    fmov d0, #-16.0
    __ fmovd(v0, -17.0);                                              //    fmov d0, #-17.0
    __ fmovd(v0, -0.125);                                             //    fmov d0, #-0.125
    __ fmovd(v0, -0.1328125);                                         //    fmov d0, #-0.1328125
    __ fmovd(v0, -0.25);                                              //    fmov d0, #-0.25
    __ fmovd(v0, -0.265625);                                          //    fmov d0, #-0.265625
    __ fmovd(v0, -0.5);                                               //    fmov d0, #-0.5
    __ fmovd(v0, -0.53125);                                           //    fmov d0, #-0.53125
    __ fmovd(v0, -1.0);                                               //    fmov d0, #-1.0
    __ fmovd(v0, -1.0625);                                            //    fmov d0, #-1.0625

// LSEOp
    __ swp(Assembler::xword, r20, r15, r15);                          //    swp x20, x15, [x15]
    __ ldadd(Assembler::xword, r7, r16, r24);                         //    ldadd x7, x16, [x24]
    __ ldbic(Assembler::xword, r17, r12, r29);                        //    ldclr x17, x12, [x29]
    __ ldeor(Assembler::xword, r13, r15, r1);                         //    ldeor x13, x15, [x1]
    __ ldorr(Assembler::xword, zr, r12, sp);                          //    ldset xzr, x12, [sp]
    __ ldsmin(Assembler::xword, r20, r15, r17);                       //    ldsmin x20, x15, [x17]
    __ ldsmax(Assembler::xword, r2, r21, r8);                         //    ldsmax x2, x21, [x8]
    __ ldumin(Assembler::xword, r22, r24, r24);                       //    ldumin x22, x24, [x24]
    __ ldumax(Assembler::xword, r22, r0, sp);                         //    ldumax x22, x0, [sp]

// LSEOp
    __ swpa(Assembler::xword, r27, r6, r4);                           //    swpa x27, x6, [x4]
    __ ldadda(Assembler::xword, r13, r13, r2);                        //    ldadda x13, x13, [x2]
    __ ldbica(Assembler::xword, r6, r25, r21);                        //    ldclra x6, x25, [x21]
    __ ldeora(Assembler::xword, r21, r16, r1);                        //    ldeora x21, x16, [x1]
    __ ldorra(Assembler::xword, r25, r9, r17);                        //    ldseta x25, x9, [x17]
    __ ldsmina(Assembler::xword, r1, r4, r24);                        //    ldsmina x1, x4, [x24]
    __ ldsmaxa(Assembler::xword, r21, r14, r6);                       //    ldsmaxa x21, x14, [x6]
    __ ldumina(Assembler::xword, r1, r14, r2);                        //    ldumina x1, x14, [x2]
    __ ldumaxa(Assembler::xword, r24, r26, r27);                      //    ldumaxa x24, x26, [x27]

// LSEOp
    __ swpal(Assembler::xword, r19, r9, r24);                         //    swpal x19, x9, [x24]
    __ ldaddal(Assembler::xword, r28, r2, r4);                        //    ldaddal x28, x2, [x4]
    __ ldbical(Assembler::xword, r12, r16, r28);                      //    ldclral x12, x16, [x28]
    __ ldeoral(Assembler::xword, r13, r27, r15);                      //    ldeoral x13, x27, [x15]
    __ ldorral(Assembler::xword, r15, r19, r26);                      //    ldsetal x15, x19, [x26]
    __ ldsminal(Assembler::xword, r30, r15, r8);                      //    ldsminal x30, x15, [x8]
    __ ldsmaxal(Assembler::xword, r15, r0, r23);                      //    ldsmaxal x15, x0, [x23]
    __ lduminal(Assembler::xword, r22, r3, r22);                      //    lduminal x22, x3, [x22]
    __ ldumaxal(Assembler::xword, r26, r3, r7);                       //    ldumaxal x26, x3, [x7]

// LSEOp
    __ swpl(Assembler::xword, r15, r30, r11);                         //    swpl x15, x30, [x11]
    __ ldaddl(Assembler::xword, r21, r16, r11);                       //    ldaddl x21, x16, [x11]
    __ ldbicl(Assembler::xword, r4, r6, r24);                         //    ldclrl x4, x6, [x24]
    __ ldeorl(Assembler::xword, r2, r1, r27);                         //    ldeorl x2, x1, [x27]
    __ ldorrl(Assembler::xword, r24, r22, r5);                        //    ldsetl x24, x22, [x5]
    __ ldsminl(Assembler::xword, r8, r20, r10);                       //    ldsminl x8, x20, [x10]
    __ ldsmaxl(Assembler::xword, r6, r0, r16);                        //    ldsmaxl x6, x0, [x16]
    __ lduminl(Assembler::xword, r13, r15, r25);                      //    lduminl x13, x15, [x25]
    __ ldumaxl(Assembler::xword, r8, r5, r2);                         //    ldumaxl x8, x5, [x2]

// LSEOp
    __ swp(Assembler::word, r13, r23, r1);                            //    swp w13, w23, [x1]
    __ ldadd(Assembler::word, r3, r10, r0);                           //    ldadd w3, w10, [x0]
    __ ldbic(Assembler::word, r16, r0, r5);                           //    ldclr w16, w0, [x5]
    __ ldeor(Assembler::word, r2, zr, r0);                            //    ldeor w2, wzr, [x0]
    __ ldorr(Assembler::word, r24, r4, r16);                          //    ldset w24, w4, [x16]
    __ ldsmin(Assembler::word, r8, r29, r27);                         //    ldsmin w8, w29, [x27]
    __ ldsmax(Assembler::word, r2, r11, r17);                         //    ldsmax w2, w11, [x17]
    __ ldumin(Assembler::word, r7, r17, r17);                         //    ldumin w7, w17, [x17]
    __ ldumax(Assembler::word, r21, r4, r16);                         //    ldumax w21, w4, [x16]

// LSEOp
    __ swpa(Assembler::word, r17, r20, r12);                          //    swpa w17, w20, [x12]
    __ ldadda(Assembler::word, r23, r16, r10);                        //    ldadda w23, w16, [x10]
    __ ldbica(Assembler::word, r2, r15, r30);                         //    ldclra w2, w15, [x30]
    __ ldeora(Assembler::word, r27, zr, r22);                         //    ldeora w27, wzr, [x22]
    __ ldorra(Assembler::word, r20, zr, r16);                         //    ldseta w20, wzr, [x16]
    __ ldsmina(Assembler::word, r16, r19, r19);                       //    ldsmina w16, w19, [x19]
    __ ldsmaxa(Assembler::word, r22, r3, r16);                        //    ldsmaxa w22, w3, [x16]
    __ ldumina(Assembler::word, r22, r16, r2);                        //    ldumina w22, w16, [x2]
    __ ldumaxa(Assembler::word, r10, r21, r12);                       //    ldumaxa w10, w21, [x12]

// LSEOp
    __ swpal(Assembler::word, r2, r14, r8);                           //    swpal w2, w14, [x8]
    __ ldaddal(Assembler::word, r3, r11, r2);                         //    ldaddal w3, w11, [x2]
    __ ldbical(Assembler::word, r16, r27, r13);                       //    ldclral w16, w27, [x13]
    __ ldeoral(Assembler::word, r19, r28, r1);                        //    ldeoral w19, w28, [x1]
    __ ldorral(Assembler::word, r4, r17, r21);                        //    ldsetal w4, w17, [x21]
    __ ldsminal(Assembler::word, r23, r8, r15);                       //    ldsminal w23, w8, [x15]
    __ ldsmaxal(Assembler::word, r25, r8, r24);                       //    ldsmaxal w25, w8, [x24]
    __ lduminal(Assembler::word, r10, r24, r11);                      //    lduminal w10, w24, [x11]
    __ ldumaxal(Assembler::word, r28, r12, r6);                       //    ldumaxal w28, w12, [x6]

// LSEOp
    __ swpl(Assembler::word, r17, r15, r8);                           //    swpl w17, w15, [x8]
    __ ldaddl(Assembler::word, r0, r7, r28);                          //    ldaddl w0, w7, [x28]
    __ ldbicl(Assembler::word, r1, r12, r26);                         //    ldclrl w1, w12, [x26]
    __ ldeorl(Assembler::word, r1, r25, r26);                         //    ldeorl w1, w25, [x26]
    __ ldorrl(Assembler::word, r25, r2, r22);                         //    ldsetl w25, w2, [x22]
    __ ldsminl(Assembler::word, r16, r19, r22);                       //    ldsminl w16, w19, [x22]
    __ ldsmaxl(Assembler::word, r9, r6, r4);                          //    ldsmaxl w9, w6, [x4]
    __ lduminl(Assembler::word, r25, r24, r24);                       //    lduminl w25, w24, [x24]
    __ ldumaxl(Assembler::word, r3, r13, r14);                        //    ldumaxl w3, w13, [x14]

    __ bind(forth);

/*
aarch64ops.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <back>:
   0:   8b46bc7d        add   x29, x3, x6, lsr #47
   4:   cb964811        sub   x17, x0, x22, asr #18
   8:   ab1bbf1a        adds   x26, x24, x27, lsl #47
   c:   eb138b1c        subs   x28, x24, x19, lsl #34
  10:   0b1e730f        add   w15, w24, w30, lsl #28
  14:   4b0a5dc4        sub   w4, w14, w10, lsl #23
  18:   2b1b5054        adds   w20, w2, w27, lsl #20
  1c:   6b02714d        subs   w13, w10, w2, lsl #28
  20:   8a511398        and   x24, x28, x17, lsr #4
  24:   aa5332cc        orr   x12, x22, x19, lsr #12
  28:   ca50721a        eor   x26, x16, x16, lsr #28
  2c:   ea44720a        ands   x10, x16, x4, lsr #28
  30:   0a4c5e31        and   w17, w17, w12, lsr #23
  34:   2a827c6d        orr   w13, w3, w2, asr #31
  38:   4a4761d8        eor   w24, w14, w7, lsr #24
  3c:   6a847f82        ands   w2, w28, w4, asr #31
  40:   8aa1f5fb        bic   x27, x15, x1, asr #61
  44:   aa6071ef        orn   x15, x15, x0, lsr #28
  48:   ca39b209        eon   x9, x16, x25, lsl #44
  4c:   ea78cfa5        bics   x5, x29, x24, lsr #51
  50:   0aab18d0        bic   w16, w6, w11, asr #6
  54:   2a2d2f2b        orn   w11, w25, w13, lsl #11
  58:   4aba2925        eon   w5, w9, w26, asr #10
  5c:   6a620702        bics   w2, w24, w2, lsr #1
  60:   1108b92c        add   w12, w9, #0x22e
  64:   31017bd9        adds   w25, w30, #0x5e
  68:   510b5d40        sub   w0, w10, #0x2d7
  6c:   7100b04e        subs   w14, w2, #0x2c
  70:   91082ba8        add   x8, x29, #0x20a
  74:   b1033d39        adds   x25, x9, #0xcf
  78:   d1049510        sub   x16, x8, #0x125
  7c:   f10c7837        subs   x23, x1, #0x31e
  80:   12088e31        and   w17, w17, #0xf000f00
  84:   3201d703        orr   w3, w24, #0x9f9f9f9f
  88:   5205c76c        eor   w12, w27, #0x18181818
  8c:   721653ca        ands   w10, w30, #0x7ffffc00
  90:   9248592c        and   x12, x9, #0xff00000000007fff
  94:   b201598d        orr   x13, x12, #0x803fffff803fffff
  98:   d245b954        eor   x20, x10, #0xf80003ffffffffff
  9c:   f25642c1        ands   x1, x22, #0x7fffc0000000000
  a0:   14000000        b   a0 <back+0xa0>
  a4:   17ffffd7        b   0 <back>
  a8:   140001ee        b   860 <forth>
  ac:   94000000        bl   ac <back+0xac>
  b0:   97ffffd4        bl   0 <back>
  b4:   940001eb        bl   860 <forth>
  b8:   3400001d        cbz   w29, b8 <back+0xb8>
  bc:   34fffa3d        cbz   w29, 0 <back>
  c0:   34003d1d        cbz   w29, 860 <forth>
  c4:   35000006        cbnz   w6, c4 <back+0xc4>
  c8:   35fff9c6        cbnz   w6, 0 <back>
  cc:   35003ca6        cbnz   w6, 860 <forth>
  d0:   b4000005        cbz   x5, d0 <back+0xd0>
  d4:   b4fff965        cbz   x5, 0 <back>
  d8:   b4003c45        cbz   x5, 860 <forth>
  dc:   b5000011        cbnz   x17, dc <back+0xdc>
  e0:   b5fff911        cbnz   x17, 0 <back>
  e4:   b5003bf1        cbnz   x17, 860 <forth>
  e8:   10000003        adr   x3, e8 <back+0xe8>
  ec:   10fff8a3        adr   x3, 0 <back>
  f0:   10003b83        adr   x3, 860 <forth>
  f4:   90000002        adrp   x2, 0 <back>
  f8:   36800016        tbz   w22, #16, f8 <back+0xf8>
  fc:   3687f836        tbz   w22, #16, 0 <back>
 100:   36803b16        tbz   w22, #16, 860 <forth>
 104:   37100015        tbnz   w21, #2, 104 <back+0x104>
 108:   3717f7d5        tbnz   w21, #2, 0 <back>
 10c:   37103ab5        tbnz   w21, #2, 860 <forth>
 110:   128deda9        mov   w9, #0xffff9092                               // #-28526
 114:   52a3773b        mov   w27, #0x1bb90000                              // #465108992
 118:   7281934d        movk   w13, #0xc9a
 11c:   92e2136a        mov   x10, #0xef64ffffffffffff                      // #-1196550125996998657
 120:   d2cdd429        mov   x9, #0x6ea100000000                           // #121637768790016
 124:   f2aa0016        movk   x22, #0x5000, lsl #16
 128:   935c7277        sbfx   x23, x19, #28, #1
 12c:   330a310c        bfxil   w12, w8, #10, #3
 130:   53081d28        lsl   w8, w9, #24
 134:   93480c2d        sbfiz   x13, x1, #56, #4
 138:   b34362ac        bfxil   x12, x21, #3, #22
 13c:   d3563a14        ubfiz   x20, x16, #42, #15
 140:   138468c9        extr   w9, w6, w4, #26
 144:   93c4ad2f        extr   x15, x9, x4, #43
 148:   54000000        b.eq   148 <back+0x148>  // b.none
 14c:   54fff5a0        b.eq   0 <back>  // b.none
 150:   54003880        b.eq   860 <forth>  // b.none
 154:   54000001        b.ne   154 <back+0x154>  // b.any
 158:   54fff541        b.ne   0 <back>  // b.any
 15c:   54003821        b.ne   860 <forth>  // b.any
 160:   54000002        b.cs   160 <back+0x160>  // b.hs, b.nlast
 164:   54fff4e2        b.cs   0 <back>  // b.hs, b.nlast
 168:   540037c2        b.cs   860 <forth>  // b.hs, b.nlast
 16c:   54000002        b.cs   16c <back+0x16c>  // b.hs, b.nlast
 170:   54fff482        b.cs   0 <back>  // b.hs, b.nlast
 174:   54003762        b.cs   860 <forth>  // b.hs, b.nlast
 178:   54000003        b.cc   178 <back+0x178>  // b.lo, b.ul, b.last
 17c:   54fff423        b.cc   0 <back>  // b.lo, b.ul, b.last
 180:   54003703        b.cc   860 <forth>  // b.lo, b.ul, b.last
 184:   54000003        b.cc   184 <back+0x184>  // b.lo, b.ul, b.last
 188:   54fff3c3        b.cc   0 <back>  // b.lo, b.ul, b.last
 18c:   540036a3        b.cc   860 <forth>  // b.lo, b.ul, b.last
 190:   54000004        b.mi   190 <back+0x190>  // b.first
 194:   54fff364        b.mi   0 <back>  // b.first
 198:   54003644        b.mi   860 <forth>  // b.first
 19c:   54000005        b.pl   19c <back+0x19c>  // b.nfrst
 1a0:   54fff305        b.pl   0 <back>  // b.nfrst
 1a4:   540035e5        b.pl   860 <forth>  // b.nfrst
 1a8:   54000006        b.vs   1a8 <back+0x1a8>
 1ac:   54fff2a6        b.vs   0 <back>
 1b0:   54003586        b.vs   860 <forth>
 1b4:   54000007        b.vc   1b4 <back+0x1b4>
 1b8:   54fff247        b.vc   0 <back>
 1bc:   54003527        b.vc   860 <forth>
 1c0:   54000008        b.hi   1c0 <back+0x1c0>  // b.pmore
 1c4:   54fff1e8        b.hi   0 <back>  // b.pmore
 1c8:   540034c8        b.hi   860 <forth>  // b.pmore
 1cc:   54000009        b.ls   1cc <back+0x1cc>  // b.plast
 1d0:   54fff189        b.ls   0 <back>  // b.plast
 1d4:   54003469        b.ls   860 <forth>  // b.plast
 1d8:   5400000a        b.ge   1d8 <back+0x1d8>  // b.tcont
 1dc:   54fff12a        b.ge   0 <back>  // b.tcont
 1e0:   5400340a        b.ge   860 <forth>  // b.tcont
 1e4:   5400000b        b.lt   1e4 <back+0x1e4>  // b.tstop
 1e8:   54fff0cb        b.lt   0 <back>  // b.tstop
 1ec:   540033ab        b.lt   860 <forth>  // b.tstop
 1f0:   5400000c        b.gt   1f0 <back+0x1f0>
 1f4:   54fff06c        b.gt   0 <back>
 1f8:   5400334c        b.gt   860 <forth>
 1fc:   5400000d        b.le   1fc <back+0x1fc>
 200:   54fff00d        b.le   0 <back>
 204:   540032ed        b.le   860 <forth>
 208:   5400000e        b.al   208 <back+0x208>
 20c:   54ffefae        b.al   0 <back>
 210:   5400328e        b.al   860 <forth>
 214:   5400000f        b.nv   214 <back+0x214>
 218:   54ffef4f        b.nv   0 <back>
 21c:   5400322f        b.nv   860 <forth>
 220:   d406b601        svc   #0x35b0
 224:   d40f9d02        hvc   #0x7ce8
 228:   d40fba23        smc   #0x7dd1
 22c:   d4244de0        brk   #0x226f
 230:   d44df200        hlt   #0x6f90
 234:   d503201f        nop
 238:   d69f03e0        eret
 23c:   d6bf03e0        drps
 240:   d5033fdf        isb
 244:   d503379f        dsb   nsh
 248:   d5033fbf        dmb   sy
 24c:   d61f03a0        br   x29
 250:   d63f0180        blr   x12
 254:   c80f7d3e        stxr   w15, x30, [x9]
 258:   c815fec5        stlxr   w21, x5, [x22]
 25c:   c85f7c0e        ldxr   x14, [x0]
 260:   c85ffc18        ldaxr   x24, [x0]
 264:   c89ffe79        stlr   x25, [x19]
 268:   c8dffd58        ldar   x24, [x10]
 26c:   880a7e35        stxr   w10, w21, [x17]
 270:   8811fcdb        stlxr   w17, w27, [x6]
 274:   885f7fa4        ldxr   w4, [x29]
 278:   885ffe21        ldaxr   w1, [x17]
 27c:   889ffeee        stlr   w14, [x23]
 280:   88dffef6        ldar   w22, [x23]
 284:   48157f20        stxrh   w21, w0, [x25]
 288:   4818fd35        stlxrh   w24, w21, [x9]
 28c:   485f7f2c        ldxrh   w12, [x25]
 290:   485ffc2b        ldaxrh   w11, [x1]
 294:   489ffd7e        stlrh   w30, [x11]
 298:   48dffda8        ldarh   w8, [x13]
 29c:   081b7f83        stxrb   w27, w3, [x28]
 2a0:   0803fdf8        stlxrb   w3, w24, [x15]
 2a4:   085f7c4d        ldxrb   w13, [x2]
 2a8:   085fffca        ldaxrb   w10, [x30]
 2ac:   089ffde7        stlrb   w7, [x15]
 2b0:   08dffd0f        ldarb   w15, [x8]
 2b4:   c87f6544        ldxp   x4, x25, [x10]
 2b8:   c87ff12b        ldaxp   x11, x28, [x9]
 2bc:   c8314126        stxp   w17, x6, x16, [x9]
 2c0:   c831a04d        stlxp   w17, x13, x8, [x2]
 2c4:   887f2829        ldxp   w9, w10, [x1]
 2c8:   887f9d62        ldaxp   w2, w7, [x11]
 2cc:   88225f3c        stxp   w2, w28, w23, [x25]
 2d0:   8836e693        stlxp   w22, w19, w25, [x20]
 2d4:   f81291f7        stur   x23, [x15, #-215]
 2d8:   b81cf105        stur   w5, [x8, #-49]
 2dc:   381f9216        sturb   w22, [x16, #-7]
 2e0:   781fb070        sturh   w16, [x3, #-5]
 2e4:   f85d10b9        ldur   x25, [x5, #-47]
 2e8:   b858e1cb        ldur   w11, [x14, #-114]
 2ec:   385f7119        ldurb   w25, [x8, #-9]
 2f0:   785cf0f6        ldurh   w22, [x7, #-49]
 2f4:   389f013c        ldursb   x28, [x9, #-16]
 2f8:   789de31b        ldursh   x27, [x24, #-34]
 2fc:   79c03ec6        ldrsh   w6, [x22, #30]
 300:   b89b91b1        ldursw   x17, [x13, #-71]
 304:   fc5613c3        ldur   d3, [x30, #-159]
 308:   bc5fd3c4        ldur   s4, [x30, #-3]
 30c:   fc195126        stur   d6, [x9, #-107]
 310:   bc1b82b6        stur   s22, [x21, #-72]
 314:   f8100c0e        str   x14, [x0, #-256]!
 318:   b81e1eae        str   w14, [x21, #-31]!
 31c:   381e5d0e        strb   w14, [x8, #-27]!
 320:   781cafcb        strh   w11, [x30, #-54]!
 324:   f85e5ca8        ldr   x8, [x5, #-27]!
 328:   b8593eaa        ldr   w10, [x21, #-109]!
 32c:   38404fa7        ldrb   w7, [x29, #4]!
 330:   7841aec2        ldrh   w2, [x22, #26]!
 334:   389fac90        ldrsb   x16, [x4, #-6]!
 338:   7880ede8        ldrsh   x8, [x15, #14]!
 33c:   78ddadd9        ldrsh   w25, [x14, #-38]!
 340:   b8818fb8        ldrsw   x24, [x29, #24]!
 344:   fc5a2ea8        ldr   d8, [x21, #-94]!
 348:   bc430dd1        ldr   s17, [x14, #48]!
 34c:   fc1d3f99        str   d25, [x28, #-45]!
 350:   bc01dd8f        str   s15, [x12, #29]!
 354:   f81834e5        str   x5, [x7], #-125
 358:   b81d87a6        str   w6, [x29], #-40
 35c:   3800c410        strb   w16, [x0], #12
 360:   7800e5f8        strh   w24, [x15], #14
 364:   f85c27b9        ldr   x25, [x29], #-62
 368:   b85ff63c        ldr   w28, [x17], #-1
 36c:   385fd689        ldrb   w9, [x20], #-3
 370:   785c77be        ldrh   w30, [x29], #-57
 374:   389eb766        ldrsb   x6, [x27], #-21
 378:   789d7575        ldrsh   x21, [x11], #-41
 37c:   78c0454d        ldrsh   w13, [x10], #4
 380:   b89a8729        ldrsw   x9, [x25], #-88
 384:   fc5a65ce        ldr   d14, [x14], #-90
 388:   bc5d5629        ldr   s9, [x17], #-43
 38c:   fc127431        str   d17, [x1], #-217
 390:   bc1b856b        str   s11, [x11], #-72
 394:   f83a6921        str   x1, [x9, x26]
 398:   b8214811        str   w17, [x0, w1, uxtw]
 39c:   38315889        strb   w9, [x4, w17, uxtw #0]
 3a0:   7838cbc0        strh   w0, [x30, w24, sxtw]
 3a4:   f87be9e0        ldr   x0, [x15, x27, sxtx]
 3a8:   b873ea93        ldr   w19, [x20, x19, sxtx]
 3ac:   3871fa2e        ldrb   w14, [x17, x17, sxtx #0]
 3b0:   7869e842        ldrh   w2, [x2, x9, sxtx]
 3b4:   38ae59f9        ldrsb   x25, [x15, w14, uxtw #0]
 3b8:   78a3da31        ldrsh   x17, [x17, w3, sxtw #1]
 3bc:   78e17b1a        ldrsh   w26, [x24, x1, lsl #1]
 3c0:   b8bbf99b        ldrsw   x27, [x12, x27, sxtx #2]
 3c4:   fc76c937        ldr   d23, [x9, w22, sxtw]
 3c8:   bc6df8e5        ldr   s5, [x7, x13, sxtx #2]
 3cc:   fc39f84f        str   d15, [x2, x25, sxtx #3]
 3d0:   bc3d6ad6        str   s22, [x22, x29]
 3d4:   f91e3af1        str   x17, [x23, #15472]
 3d8:   b91c739b        str   w27, [x28, #7280]
 3dc:   391a3308        strb   w8, [x24, #1676]
 3e0:   791bfdb7        strh   w23, [x13, #3582]
 3e4:   f95e6b6f        ldr   x15, [x27, #15568]
 3e8:   b95f9e38        ldr   w24, [x17, #8092]
 3ec:   395990e2        ldrb   w2, [x7, #1636]
 3f0:   795f69ee        ldrh   w14, [x15, #4020]
 3f4:   399c132c        ldrsb   x12, [x25, #1796]
 3f8:   799f7285        ldrsh   x5, [x20, #4024]
 3fc:   79da633c        ldrsh   w28, [x25, #3376]
 400:   b9998c11        ldrsw   x17, [x0, #6540]
 404:   fd5ea976        ldr   d22, [x11, #15696]
 408:   bd5aa63b        ldr   s27, [x17, #6820]
 40c:   fd1d0ae5        str   d5, [x23, #14864]
 410:   bd1e9922        str   s2, [x9, #7832]
 414:   5800000e        ldr   x14, 414 <back+0x414>
 418:   18000004        ldr   w4, 418 <back+0x418>
 41c:   f895b0a0        prfum   pldl1keep, [x5, #-165]
 420:   d8002200        prfm   pldl1keep, 860 <forth>
 424:   f8a469a0        prfm   pldl1keep, [x13, x4]
 428:   f9996000        prfm   pldl1keep, [x0, #12992]
 42c:   1a09019e        adc   w30, w12, w9
 430:   3a140139        adcs   w25, w9, w20
 434:   5a050065        sbc   w5, w3, w5
 438:   7a0d004c        sbcs   w12, w2, w13
 43c:   9a060281        adc   x1, x20, x6
 440:   ba040214        adcs   x20, x16, x4
 444:   da0d012c        sbc   x12, x9, x13
 448:   fa180371        sbcs   x17, x27, x24
 44c:   0b279205        add   w5, w16, w7, sxtb #4
 450:   2b3ccb73        adds   w19, w27, w28, sxtw #2
 454:   cb3ac6ee        sub   x14, x23, w26, sxtw #1
 458:   6b21e67d        subs   w29, w19, w1, sxtx #1
 45c:   8b224de0        add   x0, x15, w2, uxtw #3
 460:   ab23aa7b        adds   x27, x19, w3, sxth #2
 464:   cb3ccea2        sub   x2, x21, w28, sxtw #3
 468:   eb2fa48e        subs   x14, x4, w15, sxth #1
 46c:   3a4f32ad        ccmn   w21, w15, #0xd, cc  // cc = lo, ul, last
 470:   7a4f31e8        ccmp   w15, w15, #0x8, cc  // cc = lo, ul, last
 474:   ba49d367        ccmn   x27, x9, #0x7, le
 478:   fa4a2269        ccmp   x19, x10, #0x9, cs  // cs = hs, nlast
 47c:   3a4ac960        ccmn   w11, #0xa, #0x0, gt
 480:   7a4e3a27        ccmp   w17, #0xe, #0x7, cc  // cc = lo, ul, last
 484:   ba5b0ace        ccmn   x22, #0x1b, #0xe, eq  // eq = none
 488:   fa47d844        ccmp   x2, #0x7, #0x4, le
 48c:   1a916084        csel   w4, w4, w17, vs
 490:   1a82263a        csinc   w26, w17, w2, cs  // cs = hs, nlast
 494:   5a8eb04d        csinv   w13, w2, w14, lt  // lt = tstop
 498:   5a9e77c3        cneg   w3, w30, vs
 49c:   9a8a139a        csel   x26, x28, x10, ne  // ne = any
 4a0:   9a90642e        csinc   x14, x1, x16, vs
 4a4:   da85102b        csinv   x11, x1, x5, ne  // ne = any
 4a8:   da8e76a5        csneg   x5, x21, x14, vc
 4ac:   5ac00185        rbit   w5, w12
 4b0:   5ac00610        rev16   w16, w16
 4b4:   5ac00ba8        rev   w8, w29
 4b8:   5ac011d9        clz   w25, w14
 4bc:   5ac0141a        cls   w26, w0
 4c0:   dac000fc        rbit   x28, x7
 4c4:   dac00408        rev16   x8, x0
 4c8:   dac00aa2        rev32   x2, x21
 4cc:   dac00c25        rev   x5, x1
 4d0:   dac01388        clz   x8, x28
 4d4:   dac01551        cls   x17, x10
 4d8:   1ada0963        udiv   w3, w11, w26
 4dc:   1ad30f62        sdiv   w2, w27, w19
 4e0:   1ad7214c        lsl   w12, w10, w23
 4e4:   1ac42637        lsr   w23, w17, w4
 4e8:   1ac829b5        asr   w21, w13, w8
 4ec:   1ac42db0        ror   w16, w13, w4
 4f0:   9ac40917        udiv   x23, x8, x4
 4f4:   9ad00d07        sdiv   x7, x8, x16
 4f8:   9ac82291        lsl   x17, x20, x8
 4fc:   9ad625e7        lsr   x7, x15, x22
 500:   9ad82a6a        asr   x10, x19, x24
 504:   9ac02d77        ror   x23, x11, x0
 508:   9bc47c44        umulh   x4, x2, x4
 50c:   9b507f03        smulh   x3, x24, x16
 510:   1b0a23dd        madd   w29, w30, w10, w8
 514:   1b07f09c        msub   w28, w4, w7, w28
 518:   9b1a659a        madd   x26, x12, x26, x25
 51c:   9b179b2b        msub   x11, x25, x23, x6
 520:   9b2b2671        smaddl   x17, w19, w11, x9
 524:   9b2da5eb        smsubl   x11, w15, w13, x9
 528:   9ba302f6        umaddl   x22, w23, w3, x0
 52c:   9bafbc2e        umsubl   x14, w1, w15, x15
 530:   1e220a0f        fmul   s15, s16, s2
 534:   1e361b02        fdiv   s2, s24, s22
 538:   1e332ab1        fadd   s17, s21, s19
 53c:   1e3c3b3a        fsub   s26, s25, s28
 540:   1e2c0a09        fmul   s9, s16, s12
 544:   1e6509fa        fmul   d26, d15, d5
 548:   1e631a1a        fdiv   d26, d16, d3
 54c:   1e61298d        fadd   d13, d12, d1
 550:   1e6c3851        fsub   d17, d2, d12
 554:   1e600acb        fmul   d11, d22, d0
 558:   1f193c8a        fmadd   s10, s4, s25, s15
 55c:   1f1b8a9b        fmsub   s27, s20, s27, s2
 560:   1f376e3e        fnmadd   s30, s17, s23, s27
 564:   1f253b2e        fnmadd   s14, s25, s5, s14
 568:   1f564cd1        fmadd   d17, d6, d22, d19
 56c:   1f4fc03d        fmsub   d29, d1, d15, d16
 570:   1f735d0e        fnmadd   d14, d8, d19, d23
 574:   1f612acf        fnmadd   d15, d22, d1, d10
 578:   1e2041ba        fmov   s26, s13
 57c:   1e20c06d        fabs   s13, s3
 580:   1e2142b1        fneg   s17, s21
 584:   1e21c374        fsqrt   s20, s27
 588:   1e22c304        fcvt   d4, s24
 58c:   1e6042ac        fmov   d12, d21
 590:   1e60c2e5        fabs   d5, d23
 594:   1e614091        fneg   d17, d4
 598:   1e61c0ab        fsqrt   d11, d5
 59c:   1e62426c        fcvt   s12, d19
 5a0:   1e380343        fcvtzs   w3, s26
 5a4:   9e3803be        fcvtzs   x30, s29
 5a8:   1e78016b        fcvtzs   w11, d11
 5ac:   9e7800f5        fcvtzs   x21, d7
 5b0:   1e2203c4        scvtf   s4, w30
 5b4:   9e22015c        scvtf   s28, x10
 5b8:   1e62002d        scvtf   d13, w1
 5bc:   9e62012b        scvtf   d11, x9
 5c0:   1e2602ef        fmov   w15, s23
 5c4:   9e660231        fmov   x17, d17
 5c8:   1e2701f8        fmov   s24, w15
 5cc:   9e670238        fmov   d24, x17
 5d0:   1e2823a0        fcmp   s29, s8
 5d4:   1e752060        fcmp   d3, d21
 5d8:   1e202008        fcmp   s0, #0.0
 5dc:   1e602128        fcmp   d9, #0.0
 5e0:   29000ace        stp   w14, w2, [x22]
 5e4:   294e7aca        ldp   w10, w30, [x22, #112]
 5e8:   69747929        ldpsw   x9, x30, [x9, #-96]
 5ec:   a9086da7        stp   x7, x27, [x13, #128]
 5f0:   a978569a        ldp   x26, x21, [x20, #-128]
 5f4:   29a646d5        stp   w21, w17, [x22, #-208]!
 5f8:   29e238a8        ldp   w8, w14, [x5, #-240]!
 5fc:   69e4546f        ldpsw   x15, x21, [x3, #-224]!
 600:   a9b12bca        stp   x10, x10, [x30, #-240]!
 604:   a9f117a6        ldp   x6, x5, [x29, #-240]!
 608:   28bc5222        stp   w2, w20, [x17], #-32
 60c:   28ea1590        ldp   w16, w5, [x12], #-176
 610:   68c633dd        ldpsw   x29, x12, [x30], #48
 614:   a8876117        stp   x23, x24, [x8], #112
 618:   a8fa1b84        ldp   x4, x6, [x28], #-96
 61c:   28020a66        stnp   w6, w2, [x19, #16]
 620:   284a2f65        ldnp   w5, w11, [x27, #80]
 624:   a8064c2c        stnp   x12, x19, [x1, #96]
 628:   a84142a5        ldnp   x5, x16, [x21, #16]
 62c:   0c40729c        ld1   {v28.8b}, [x20]
 630:   4cdfa079        ld1   {v25.16b, v26.16b}, [x3], #32
 634:   0cca6f3e        ld1   {v30.1d, v31.1d, v0.1d}, [x25], x10
 638:   4cdf24b3        ld1   {v19.8h-v22.8h}, [x5], #64
 63c:   0d40c34c        ld1r   {v12.8b}, [x26]
 640:   4ddfcb6d        ld1r   {v13.4s}, [x27], #4
 644:   0dc8cd1a        ld1r   {v26.1d}, [x8], x8
 648:   4c408f1b        ld2   {v27.2d, v28.2d}, [x24]
 64c:   0cdf8501        ld2   {v1.4h, v2.4h}, [x8], #16
 650:   4d60c0e9        ld2r   {v9.16b, v10.16b}, [x7]
 654:   0dffc88c        ld2r   {v12.2s, v13.2s}, [x4], #8
 658:   4dedcc60        ld2r   {v0.2d, v1.2d}, [x3], x13
 65c:   4cd348d6        ld3   {v22.4s-v24.4s}, [x6], x19
 660:   0c404903        ld3   {v3.2s-v5.2s}, [x8]
 664:   4d40e50b        ld3r   {v11.8h-v13.8h}, [x8]
 668:   4ddfebd0        ld3r   {v16.4s-v18.4s}, [x30], #12
 66c:   0dcdeddc        ld3r   {v28.1d-v30.1d}, [x14], x13
 670:   4cdf0740        ld4   {v0.8h-v3.8h}, [x26], #64
 674:   0cd102c1        ld4   {v1.8b-v4.8b}, [x22], x17
 678:   0d60e221        ld4r   {v1.8b-v4.8b}, [x17]
 67c:   0dffe677        ld4r   {v23.4h-v26.4h}, [x19], #8
 680:   0de3e89b        ld4r   {v27.2s-v30.2s}, [x4], x3
 684:   ba5fd3e3        ccmn   xzr, xzr, #0x3, le
 688:   3a5f03e5        ccmn   wzr, wzr, #0x5, eq  // eq = none
 68c:   fa411be4        ccmp   xzr, #0x1, #0x4, ne  // ne = any
 690:   7a42cbe2        ccmp   wzr, #0x2, #0x2, gt
 694:   93df03ff        ror   xzr, xzr, #0
 698:   c820ffff        stlxp   w0, xzr, xzr, [sp]
 69c:   8822fc7f        stlxp   w2, wzr, wzr, [x3]
 6a0:   c8247cbf        stxp   w4, xzr, xzr, [x5]
 6a4:   88267fff        stxp   w6, wzr, wzr, [sp]
 6a8:   4e010fe0        dup   v0.16b, wzr
 6ac:   4e081fe1        mov   v1.d[0], xzr
 6b0:   4e0c1fe1        mov   v1.s[1], wzr
 6b4:   4e0a1fe1        mov   v1.h[2], wzr
 6b8:   4e071fe1        mov   v1.b[3], wzr
 6bc:   4cc0ac3f        ld1   {v31.2d, v0.2d}, [x1], x0
 6c0:   1e601000        fmov   d0, #2.000000000000000000e+00
 6c4:   1e603000        fmov   d0, #2.125000000000000000e+00
 6c8:   1e621000        fmov   d0, #4.000000000000000000e+00
 6cc:   1e623000        fmov   d0, #4.250000000000000000e+00
 6d0:   1e641000        fmov   d0, #8.000000000000000000e+00
 6d4:   1e643000        fmov   d0, #8.500000000000000000e+00
 6d8:   1e661000        fmov   d0, #1.600000000000000000e+01
 6dc:   1e663000        fmov   d0, #1.700000000000000000e+01
 6e0:   1e681000        fmov   d0, #1.250000000000000000e-01
 6e4:   1e683000        fmov   d0, #1.328125000000000000e-01
 6e8:   1e6a1000        fmov   d0, #2.500000000000000000e-01
 6ec:   1e6a3000        fmov   d0, #2.656250000000000000e-01
 6f0:   1e6c1000        fmov   d0, #5.000000000000000000e-01
 6f4:   1e6c3000        fmov   d0, #5.312500000000000000e-01
 6f8:   1e6e1000        fmov   d0, #1.000000000000000000e+00
 6fc:   1e6e3000        fmov   d0, #1.062500000000000000e+00
 700:   1e701000        fmov   d0, #-2.000000000000000000e+00
 704:   1e703000        fmov   d0, #-2.125000000000000000e+00
 708:   1e721000        fmov   d0, #-4.000000000000000000e+00
 70c:   1e723000        fmov   d0, #-4.250000000000000000e+00
 710:   1e741000        fmov   d0, #-8.000000000000000000e+00
 714:   1e743000        fmov   d0, #-8.500000000000000000e+00
 718:   1e761000        fmov   d0, #-1.600000000000000000e+01
 71c:   1e763000        fmov   d0, #-1.700000000000000000e+01
 720:   1e781000        fmov   d0, #-1.250000000000000000e-01
 724:   1e783000        fmov   d0, #-1.328125000000000000e-01
 728:   1e7a1000        fmov   d0, #-2.500000000000000000e-01
 72c:   1e7a3000        fmov   d0, #-2.656250000000000000e-01
 730:   1e7c1000        fmov   d0, #-5.000000000000000000e-01
 734:   1e7c3000        fmov   d0, #-5.312500000000000000e-01
 738:   1e7e1000        fmov   d0, #-1.000000000000000000e+00
 73c:   1e7e3000        fmov   d0, #-1.062500000000000000e+00
 740:   f83481ef        swp   x20, x15, [x15]
 744:   f8270310        ldadd   x7, x16, [x24]
 748:   f83113ac        ldclr   x17, x12, [x29]
 74c:   f82d202f        ldeor   x13, x15, [x1]
 750:   f83f33ec        ldset   xzr, x12, [sp]
 754:   f834522f        ldsmin   x20, x15, [x17]
 758:   f8224115        ldsmax   x2, x21, [x8]
 75c:   f8367318        ldumin   x22, x24, [x24]
 760:   f83663e0        ldumax   x22, x0, [sp]
 764:   f8bb8086        swpa   x27, x6, [x4]
 768:   f8ad004d        ldadda   x13, x13, [x2]
 76c:   f8a612b9        ldclra   x6, x25, [x21]
 770:   f8b52030        ldeora   x21, x16, [x1]
 774:   f8b93229        ldseta   x25, x9, [x17]
 778:   f8a15304        ldsmina   x1, x4, [x24]
 77c:   f8b540ce        ldsmaxa   x21, x14, [x6]
 780:   f8a1704e        ldumina   x1, x14, [x2]
 784:   f8b8637a        ldumaxa   x24, x26, [x27]
 788:   f8f38309        swpal   x19, x9, [x24]
 78c:   f8fc0082        ldaddal   x28, x2, [x4]
 790:   f8ec1390        ldclral   x12, x16, [x28]
 794:   f8ed21fb        ldeoral   x13, x27, [x15]
 798:   f8ef3353        ldsetal   x15, x19, [x26]
 79c:   f8fe510f        ldsminal   x30, x15, [x8]
 7a0:   f8ef42e0        ldsmaxal   x15, x0, [x23]
 7a4:   f8f672c3        lduminal   x22, x3, [x22]
 7a8:   f8fa60e3        ldumaxal   x26, x3, [x7]
 7ac:   f86f817e        swpl   x15, x30, [x11]
 7b0:   f8750170        ldaddl   x21, x16, [x11]
 7b4:   f8641306        ldclrl   x4, x6, [x24]
 7b8:   f8622361        ldeorl   x2, x1, [x27]
 7bc:   f87830b6        ldsetl   x24, x22, [x5]
 7c0:   f8685154        ldsminl   x8, x20, [x10]
 7c4:   f8664200        ldsmaxl   x6, x0, [x16]
 7c8:   f86d732f        lduminl   x13, x15, [x25]
 7cc:   f8686045        ldumaxl   x8, x5, [x2]
 7d0:   b82d8037        swp   w13, w23, [x1]
 7d4:   b823000a        ldadd   w3, w10, [x0]
 7d8:   b83010a0        ldclr   w16, w0, [x5]
 7dc:   b822201f        steor   w2, [x0]
 7e0:   b8383204        ldset   w24, w4, [x16]
 7e4:   b828537d        ldsmin   w8, w29, [x27]
 7e8:   b822422b        ldsmax   w2, w11, [x17]
 7ec:   b8277231        ldumin   w7, w17, [x17]
 7f0:   b8356204        ldumax   w21, w4, [x16]
 7f4:   b8b18194        swpa   w17, w20, [x12]
 7f8:   b8b70150        ldadda   w23, w16, [x10]
 7fc:   b8a213cf        ldclra   w2, w15, [x30]
 800:   b8bb22df        ldeora   w27, wzr, [x22]
 804:   b8b4321f        ldseta   w20, wzr, [x16]
 808:   b8b05273        ldsmina   w16, w19, [x19]
 80c:   b8b64203        ldsmaxa   w22, w3, [x16]
 810:   b8b67050        ldumina   w22, w16, [x2]
 814:   b8aa6195        ldumaxa   w10, w21, [x12]
 818:   b8e2810e        swpal   w2, w14, [x8]
 81c:   b8e3004b        ldaddal   w3, w11, [x2]
 820:   b8f011bb        ldclral   w16, w27, [x13]
 824:   b8f3203c        ldeoral   w19, w28, [x1]
 828:   b8e432b1        ldsetal   w4, w17, [x21]
 82c:   b8f751e8        ldsminal   w23, w8, [x15]
 830:   b8f94308        ldsmaxal   w25, w8, [x24]
 834:   b8ea7178        lduminal   w10, w24, [x11]
 838:   b8fc60cc        ldumaxal   w28, w12, [x6]
 83c:   b871810f        swpl   w17, w15, [x8]
 840:   b8600387        ldaddl   w0, w7, [x28]
 844:   b861134c        ldclrl   w1, w12, [x26]
 848:   b8612359        ldeorl   w1, w25, [x26]
 84c:   b87932c2        ldsetl   w25, w2, [x22]
 850:   b87052d3        ldsminl   w16, w19, [x22]
 854:   b8694086        ldsmaxl   w9, w6, [x4]
 858:   b8797318        lduminl   w25, w24, [x24]
 85c:   b86361cd        ldumaxl   w3, w13, [x14]
 */

  static const unsigned int insns[] =
  {
    0x8b46bc7d,     0xcb964811,     0xab1bbf1a,     0xeb138b1c,
    0x0b1e730f,     0x4b0a5dc4,     0x2b1b5054,     0x6b02714d,
    0x8a511398,     0xaa5332cc,     0xca50721a,     0xea44720a,
    0x0a4c5e31,     0x2a827c6d,     0x4a4761d8,     0x6a847f82,
    0x8aa1f5fb,     0xaa6071ef,     0xca39b209,     0xea78cfa5,
    0x0aab18d0,     0x2a2d2f2b,     0x4aba2925,     0x6a620702,
    0x1108b92c,     0x31017bd9,     0x510b5d40,     0x7100b04e,
    0x91082ba8,     0xb1033d39,     0xd1049510,     0xf10c7837,
    0x12088e31,     0x3201d703,     0x5205c76c,     0x721653ca,
    0x9248592c,     0xb201598d,     0xd245b954,     0xf25642c1,
    0x14000000,     0x17ffffd7,     0x140001ee,     0x94000000,
    0x97ffffd4,     0x940001eb,     0x3400001d,     0x34fffa3d,
    0x34003d1d,     0x35000006,     0x35fff9c6,     0x35003ca6,
    0xb4000005,     0xb4fff965,     0xb4003c45,     0xb5000011,
    0xb5fff911,     0xb5003bf1,     0x10000003,     0x10fff8a3,
    0x10003b83,     0x90000002,     0x36800016,     0x3687f836,
    0x36803b16,     0x37100015,     0x3717f7d5,     0x37103ab5,
    0x128deda9,     0x52a3773b,     0x7281934d,     0x92e2136a,
    0xd2cdd429,     0xf2aa0016,     0x935c7277,     0x330a310c,
    0x53081d28,     0x93480c2d,     0xb34362ac,     0xd3563a14,
    0x138468c9,     0x93c4ad2f,     0x54000000,     0x54fff5a0,
    0x54003880,     0x54000001,     0x54fff541,     0x54003821,
    0x54000002,     0x54fff4e2,     0x540037c2,     0x54000002,
    0x54fff482,     0x54003762,     0x54000003,     0x54fff423,
    0x54003703,     0x54000003,     0x54fff3c3,     0x540036a3,
    0x54000004,     0x54fff364,     0x54003644,     0x54000005,
    0x54fff305,     0x540035e5,     0x54000006,     0x54fff2a6,
    0x54003586,     0x54000007,     0x54fff247,     0x54003527,
    0x54000008,     0x54fff1e8,     0x540034c8,     0x54000009,
    0x54fff189,     0x54003469,     0x5400000a,     0x54fff12a,
    0x5400340a,     0x5400000b,     0x54fff0cb,     0x540033ab,
    0x5400000c,     0x54fff06c,     0x5400334c,     0x5400000d,
    0x54fff00d,     0x540032ed,     0x5400000e,     0x54ffefae,
    0x5400328e,     0x5400000f,     0x54ffef4f,     0x5400322f,
    0xd406b601,     0xd40f9d02,     0xd40fba23,     0xd4244de0,
    0xd44df200,     0xd503201f,     0xd69f03e0,     0xd6bf03e0,
    0xd5033fdf,     0xd503379f,     0xd5033fbf,     0xd61f03a0,
    0xd63f0180,     0xc80f7d3e,     0xc815fec5,     0xc85f7c0e,
    0xc85ffc18,     0xc89ffe79,     0xc8dffd58,     0x880a7e35,
    0x8811fcdb,     0x885f7fa4,     0x885ffe21,     0x889ffeee,
    0x88dffef6,     0x48157f20,     0x4818fd35,     0x485f7f2c,
    0x485ffc2b,     0x489ffd7e,     0x48dffda8,     0x081b7f83,
    0x0803fdf8,     0x085f7c4d,     0x085fffca,     0x089ffde7,
    0x08dffd0f,     0xc87f6544,     0xc87ff12b,     0xc8314126,
    0xc831a04d,     0x887f2829,     0x887f9d62,     0x88225f3c,
    0x8836e693,     0xf81291f7,     0xb81cf105,     0x381f9216,
    0x781fb070,     0xf85d10b9,     0xb858e1cb,     0x385f7119,
    0x785cf0f6,     0x389f013c,     0x789de31b,     0x79c03ec6,
    0xb89b91b1,     0xfc5613c3,     0xbc5fd3c4,     0xfc195126,
    0xbc1b82b6,     0xf8100c0e,     0xb81e1eae,     0x381e5d0e,
    0x781cafcb,     0xf85e5ca8,     0xb8593eaa,     0x38404fa7,
    0x7841aec2,     0x389fac90,     0x7880ede8,     0x78ddadd9,
    0xb8818fb8,     0xfc5a2ea8,     0xbc430dd1,     0xfc1d3f99,
    0xbc01dd8f,     0xf81834e5,     0xb81d87a6,     0x3800c410,
    0x7800e5f8,     0xf85c27b9,     0xb85ff63c,     0x385fd689,
    0x785c77be,     0x389eb766,     0x789d7575,     0x78c0454d,
    0xb89a8729,     0xfc5a65ce,     0xbc5d5629,     0xfc127431,
    0xbc1b856b,     0xf83a6921,     0xb8214811,     0x38315889,
    0x7838cbc0,     0xf87be9e0,     0xb873ea93,     0x3871fa2e,
    0x7869e842,     0x38ae59f9,     0x78a3da31,     0x78e17b1a,
    0xb8bbf99b,     0xfc76c937,     0xbc6df8e5,     0xfc39f84f,
    0xbc3d6ad6,     0xf91e3af1,     0xb91c739b,     0x391a3308,
    0x791bfdb7,     0xf95e6b6f,     0xb95f9e38,     0x395990e2,
    0x795f69ee,     0x399c132c,     0x799f7285,     0x79da633c,
    0xb9998c11,     0xfd5ea976,     0xbd5aa63b,     0xfd1d0ae5,
    0xbd1e9922,     0x5800000e,     0x18000004,     0xf895b0a0,
    0xd8002200,     0xf8a469a0,     0xf9996000,     0x1a09019e,
    0x3a140139,     0x5a050065,     0x7a0d004c,     0x9a060281,
    0xba040214,     0xda0d012c,     0xfa180371,     0x0b279205,
    0x2b3ccb73,     0xcb3ac6ee,     0x6b21e67d,     0x8b224de0,
    0xab23aa7b,     0xcb3ccea2,     0xeb2fa48e,     0x3a4f32ad,
    0x7a4f31e8,     0xba49d367,     0xfa4a2269,     0x3a4ac960,
    0x7a4e3a27,     0xba5b0ace,     0xfa47d844,     0x1a916084,
    0x1a82263a,     0x5a8eb04d,     0x5a9e77c3,     0x9a8a139a,
    0x9a90642e,     0xda85102b,     0xda8e76a5,     0x5ac00185,
    0x5ac00610,     0x5ac00ba8,     0x5ac011d9,     0x5ac0141a,
    0xdac000fc,     0xdac00408,     0xdac00aa2,     0xdac00c25,
    0xdac01388,     0xdac01551,     0x1ada0963,     0x1ad30f62,
    0x1ad7214c,     0x1ac42637,     0x1ac829b5,     0x1ac42db0,
    0x9ac40917,     0x9ad00d07,     0x9ac82291,     0x9ad625e7,
    0x9ad82a6a,     0x9ac02d77,     0x9bc47c44,     0x9b507f03,
    0x1b0a23dd,     0x1b07f09c,     0x9b1a659a,     0x9b179b2b,
    0x9b2b2671,     0x9b2da5eb,     0x9ba302f6,     0x9bafbc2e,
    0x1e220a0f,     0x1e361b02,     0x1e332ab1,     0x1e3c3b3a,
    0x1e2c0a09,     0x1e6509fa,     0x1e631a1a,     0x1e61298d,
    0x1e6c3851,     0x1e600acb,     0x1f193c8a,     0x1f1b8a9b,
    0x1f376e3e,     0x1f253b2e,     0x1f564cd1,     0x1f4fc03d,
    0x1f735d0e,     0x1f612acf,     0x1e2041ba,     0x1e20c06d,
    0x1e2142b1,     0x1e21c374,     0x1e22c304,     0x1e6042ac,
    0x1e60c2e5,     0x1e614091,     0x1e61c0ab,     0x1e62426c,
    0x1e380343,     0x9e3803be,     0x1e78016b,     0x9e7800f5,
    0x1e2203c4,     0x9e22015c,     0x1e62002d,     0x9e62012b,
    0x1e2602ef,     0x9e660231,     0x1e2701f8,     0x9e670238,
    0x1e2823a0,     0x1e752060,     0x1e202008,     0x1e602128,
    0x29000ace,     0x294e7aca,     0x69747929,     0xa9086da7,
    0xa978569a,     0x29a646d5,     0x29e238a8,     0x69e4546f,
    0xa9b12bca,     0xa9f117a6,     0x28bc5222,     0x28ea1590,
    0x68c633dd,     0xa8876117,     0xa8fa1b84,     0x28020a66,
    0x284a2f65,     0xa8064c2c,     0xa84142a5,     0x0c40729c,
    0x4cdfa079,     0x0cca6f3e,     0x4cdf24b3,     0x0d40c34c,
    0x4ddfcb6d,     0x0dc8cd1a,     0x4c408f1b,     0x0cdf8501,
    0x4d60c0e9,     0x0dffc88c,     0x4dedcc60,     0x4cd348d6,
    0x0c404903,     0x4d40e50b,     0x4ddfebd0,     0x0dcdeddc,
    0x4cdf0740,     0x0cd102c1,     0x0d60e221,     0x0dffe677,
    0x0de3e89b,     0xba5fd3e3,     0x3a5f03e5,     0xfa411be4,
    0x7a42cbe2,     0x93df03ff,     0xc820ffff,     0x8822fc7f,
    0xc8247cbf,     0x88267fff,     0x4e010fe0,     0x4e081fe1,
    0x4e0c1fe1,     0x4e0a1fe1,     0x4e071fe1,     0x4cc0ac3f,
    0x1e601000,     0x1e603000,     0x1e621000,     0x1e623000,
    0x1e641000,     0x1e643000,     0x1e661000,     0x1e663000,
    0x1e681000,     0x1e683000,     0x1e6a1000,     0x1e6a3000,
    0x1e6c1000,     0x1e6c3000,     0x1e6e1000,     0x1e6e3000,
    0x1e701000,     0x1e703000,     0x1e721000,     0x1e723000,
    0x1e741000,     0x1e743000,     0x1e761000,     0x1e763000,
    0x1e781000,     0x1e783000,     0x1e7a1000,     0x1e7a3000,
    0x1e7c1000,     0x1e7c3000,     0x1e7e1000,     0x1e7e3000,
    0xf83481ef,     0xf8270310,     0xf83113ac,     0xf82d202f,
    0xf83f33ec,     0xf834522f,     0xf8224115,     0xf8367318,
    0xf83663e0,     0xf8bb8086,     0xf8ad004d,     0xf8a612b9,
    0xf8b52030,     0xf8b93229,     0xf8a15304,     0xf8b540ce,
    0xf8a1704e,     0xf8b8637a,     0xf8f38309,     0xf8fc0082,
    0xf8ec1390,     0xf8ed21fb,     0xf8ef3353,     0xf8fe510f,
    0xf8ef42e0,     0xf8f672c3,     0xf8fa60e3,     0xf86f817e,
    0xf8750170,     0xf8641306,     0xf8622361,     0xf87830b6,
    0xf8685154,     0xf8664200,     0xf86d732f,     0xf8686045,
    0xb82d8037,     0xb823000a,     0xb83010a0,     0xb822201f,
    0xb8383204,     0xb828537d,     0xb822422b,     0xb8277231,
    0xb8356204,     0xb8b18194,     0xb8b70150,     0xb8a213cf,
    0xb8bb22df,     0xb8b4321f,     0xb8b05273,     0xb8b64203,
    0xb8b67050,     0xb8aa6195,     0xb8e2810e,     0xb8e3004b,
    0xb8f011bb,     0xb8f3203c,     0xb8e432b1,     0xb8f751e8,
    0xb8f94308,     0xb8ea7178,     0xb8fc60cc,     0xb871810f,
    0xb8600387,     0xb861134c,     0xb8612359,     0xb87932c2,
    0xb87052d3,     0xb8694086,     0xb8797318,     0xb86361cd
  };
// END  Generated code -- do not edit

  asm_check((unsigned int *)entry, insns, sizeof insns / sizeof insns[0]);

  {
    address PC = __ pc();
    __ ld1(v0, __ T16B, Address(r16));      // No offset
    __ ld1(v0, __ T8H, __ post(r16, 16));   // Post-index
    __ ld2(v0, v1, __ T8H, __ post(r24, 16 * 2));   // Post-index
    __ ld1(v0, __ T16B, __ post(r16, r17)); // Register post-index
    static const unsigned int vector_insns[] = {
       0x4c407200, // ld1   {v0.16b}, [x16]
       0x4cdf7600, // ld1   {v0.8h}, [x16], #16
       0x4cdf8700, // ld2   {v0.8h, v1.8h}, [x24], #32
       0x4cd17200, // ld1   {v0.16b}, [x16], x17
      };
    asm_check((unsigned int *)PC, vector_insns,
              sizeof vector_insns / sizeof vector_insns[0]);
  }
}
#endif // ASSERT

#undef __

void Assembler::emit_data64(jlong data,
                            relocInfo::relocType rtype,
                            int format) {
  if (rtype == relocInfo::none) {
    emit_int64(data);
  } else {
    emit_data64(data, Relocation::spec_simple(rtype), format);
  }
}

void Assembler::emit_data64(jlong data,
                            RelocationHolder const& rspec,
                            int format) {

  assert(inst_mark() != NULL, "must be inside InstructionMark");
  // Do not use AbstractAssembler::relocate, which is not intended for
  // embedded words.  Instead, relocate to the enclosing instruction.
  code_section()->relocate(inst_mark(), rspec, format);
  emit_int64(data);
}

extern "C" {
  void das(uint64_t start, int len) {
    ResourceMark rm;
    len <<= 2;
    if (len < 0)
      Disassembler::decode((address)start + len, (address)start);
    else
      Disassembler::decode((address)start, (address)start + len);
  }

  JNIEXPORT void das1(uintptr_t insn) {
    das(insn, 1);
  }
}

#define gas_assert(ARG1) assert(ARG1, #ARG1)

#define __ as->

void Address::lea(MacroAssembler *as, Register r) const {
  Relocation* reloc = _rspec.reloc();
  relocInfo::relocType rtype = (relocInfo::relocType) reloc->type();

  switch(_mode) {
  case base_plus_offset: {
    if (_offset == 0 && _base == r) // it's a nop
      break;
    if (_offset > 0)
      __ add(r, _base, _offset);
    else
      __ sub(r, _base, -_offset);
      break;
  }
  case base_plus_offset_reg: {
    __ add(r, _base, _index, _ext.op(), MAX2(_ext.shift(), 0));
    break;
  }
  case literal: {
    if (rtype == relocInfo::none)
      __ mov(r, target());
    else
      __ movptr(r, (uint64_t)target());
    break;
  }
  default:
    ShouldNotReachHere();
  }
}

void Assembler::adrp(Register reg1, const Address &dest, uint64_t &byte_offset) {
  ShouldNotReachHere();
}

#undef __

#define starti Instruction_aarch64 do_not_use(this); set_current(&do_not_use)

  void Assembler::adr(Register Rd, address adr) {
    intptr_t offset = adr - pc();
    int offset_lo = offset & 3;
    offset >>= 2;
    starti;
    f(0, 31), f(offset_lo, 30, 29), f(0b10000, 28, 24), sf(offset, 23, 5);
    rf(Rd, 0);
  }

  void Assembler::_adrp(Register Rd, address adr) {
    uint64_t pc_page = (uint64_t)pc() >> 12;
    uint64_t adr_page = (uint64_t)adr >> 12;
    intptr_t offset = adr_page - pc_page;
    int offset_lo = offset & 3;
    offset >>= 2;
    starti;
    f(1, 31), f(offset_lo, 30, 29), f(0b10000, 28, 24), sf(offset, 23, 5);
    rf(Rd, 0);
  }

#undef starti

Address::Address(address target, relocInfo::relocType rtype) : _mode(literal){
  _is_lval = false;
  _target = target;
  switch (rtype) {
  case relocInfo::oop_type:
  case relocInfo::metadata_type:
    // Oops are a special case. Normally they would be their own section
    // but in cases like icBuffer they are literals in the code stream that
    // we don't have a section for. We use none so that we get a literal address
    // which is always patchable.
    break;
  case relocInfo::external_word_type:
    _rspec = external_word_Relocation::spec(target);
    break;
  case relocInfo::internal_word_type:
    _rspec = internal_word_Relocation::spec(target);
    break;
  case relocInfo::opt_virtual_call_type:
    _rspec = opt_virtual_call_Relocation::spec();
    break;
  case relocInfo::static_call_type:
    _rspec = static_call_Relocation::spec();
    break;
  case relocInfo::runtime_call_type:
    _rspec = runtime_call_Relocation::spec();
    break;
  case relocInfo::poll_type:
  case relocInfo::poll_return_type:
    _rspec = Relocation::spec_simple(rtype);
    break;
  case relocInfo::none:
    _rspec = RelocationHolder::none;
    break;
  default:
    ShouldNotReachHere();
    break;
  }
}

void Assembler::b(const Address &dest) {
  code_section()->relocate(pc(), dest.rspec());
  b(dest.target());
}

void Assembler::bl(const Address &dest) {
  code_section()->relocate(pc(), dest.rspec());
  bl(dest.target());
}

void Assembler::adr(Register r, const Address &dest) {
  code_section()->relocate(pc(), dest.rspec());
  adr(r, dest.target());
}

void Assembler::br(Condition cc, Label &L) {
  if (L.is_bound()) {
    br(cc, target(L));
  } else {
    L.add_patch_at(code(), locator());
    br(cc, pc());
  }
}

void Assembler::wrap_label(Label &L,
                                 Assembler::uncond_branch_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(target(L));
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(pc());
  }
}

void Assembler::wrap_label(Register r, Label &L,
                                 compare_and_branch_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(r, target(L));
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(r, pc());
  }
}

void Assembler::wrap_label(Register r, int bitpos, Label &L,
                                 test_and_branch_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(r, bitpos, target(L));
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(r, bitpos, pc());
  }
}

void Assembler::wrap_label(Label &L, prfop op, prefetch_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(target(L), op);
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(pc(), op);
  }
}

// An "all-purpose" add/subtract immediate, per ARM documentation:
// A "programmer-friendly" assembler may accept a negative immediate
// between -(2^24 -1) and -1 inclusive, causing it to convert a
// requested ADD operation to a SUB, or vice versa, and then encode
// the absolute value of the immediate as for uimm24.
void Assembler::add_sub_immediate(Register Rd, Register Rn, unsigned uimm, int op,
                                  int negated_op) {
  bool sets_flags = op & 1;   // this op sets flags
  union {
    unsigned u;
    int imm;
  };
  u = uimm;
  bool shift = false;
  bool neg = imm < 0;
  if (neg) {
    imm = -imm;
    op = negated_op;
  }
  assert(Rd != sp || imm % 16 == 0, "misaligned stack");
  if (imm >= (1 << 11)
      && ((imm >> 12) << 12 == imm)) {
    imm >>= 12;
    shift = true;
  }
  f(op, 31, 29), f(0b10001, 28, 24), f(shift, 23, 22), f(imm, 21, 10);

  // add/subtract immediate ops with the S bit set treat r31 as zr;
  // with S unset they use sp.
  if (sets_flags)
    zrf(Rd, 0);
  else
    srf(Rd, 0);

  srf(Rn, 5);
}

bool Assembler::operand_valid_for_add_sub_immediate(int64_t imm) {
  uint64_t uimm = (uint64_t)uabs((jlong)imm);
  if (uimm < (1 << 12))
    return true;
  if (uimm < (1 << 24)
      && ((uimm >> 12) << 12 == uimm)) {
    return true;
  }
  return false;
}

bool Assembler::operand_valid_for_logical_immediate(bool is32, uint64_t imm) {
  return encode_logical_immediate(is32, imm) != 0xffffffff;
}

static uint64_t doubleTo64Bits(jdouble d) {
  union {
    jdouble double_value;
    uint64_t double_bits;
  };

  double_value = d;
  return double_bits;
}

bool Assembler::operand_valid_for_float_immediate(double imm) {
  // If imm is all zero bits we can use ZR as the source of a
  // floating-point value.
  if (doubleTo64Bits(imm) == 0)
    return true;

  // Otherwise try to encode imm then convert the encoded value back
  // and make sure it's the exact same bit pattern.
  unsigned result = encoding_for_fp_immediate(imm);
  return doubleTo64Bits(imm) == fp_immediate_for_encoding(result, true);
}

int AbstractAssembler::code_fill_byte() {
  return 0;
}

// n.b. this is implemented in subclass MacroAssembler
void Assembler::bang_stack_with_offset(int offset) { Unimplemented(); }


// and now the routines called by the assembler which encapsulate the
// above encode and decode functions

uint32_t
asm_util::encode_logical_immediate(bool is32, uint64_t imm)
{
  if (is32) {
    /* Allow all zeros or all ones in top 32-bits, so that
       constant expressions like ~1 are permitted. */
    if (imm >> 32 != 0 && imm >> 32 != 0xffffffff)
      return 0xffffffff;
    /* Replicate the 32 lower bits to the 32 upper bits.  */
    imm &= 0xffffffff;
    imm |= imm << 32;
  }

  return encoding_for_logical_immediate(imm);
}

unsigned Assembler::pack(double value) {
  float val = (float)value;
  unsigned result = encoding_for_fp_immediate(val);
  guarantee(unpack(result) == value,
            "Invalid floating-point immediate operand");
  return result;
}

// Packed operands for  Floating-point Move (immediate)

static float unpack(unsigned value) {
  union {
    unsigned ival;
    float val;
  };
  ival = fp_immediate_for_encoding(value, 0);
  return val;
}

address Assembler::locate_next_instruction(address inst) {
  return inst + Assembler::instruction_size;
}
